{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1.0, shape=(), dtype=float32)\n",
      "tf.Tensor(2.0, shape=(), dtype=float32)\n",
      "tf.Tensor(3.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(9.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#스칼라 정의\n",
    "a = tf.constant(1)\n",
    "b = tf.constant(2)\n",
    "print(a)\n",
    "print(b)\n",
    "print(tf.rank(a)) #차원 확인\n",
    "a = tf.cast(a,tf.float32)\n",
    "b = tf.cast(b,tf.float32)\n",
    "print(a)\n",
    "print(b)\n",
    "#계산 : add(덧셈), subtract(뺄셈), multiply(곱셈), divide(나눗셈), mod(나눗셈_나머지), floordiv(나눗셈_몫),square(거듭제곱),sqrt(제곱근),\n",
    "c = tf.math.add(a,b)\n",
    "d = tf.math.square(c)\n",
    "print(c)\n",
    "print(tf.rank(c)) #차원 확인\n",
    "print(d)\n",
    "print(tf.rank(d)) #차원 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([10. 20. 30.], shape=(3,), dtype=float32)\n",
      "tf.Tensor([10. 10. 10.], shape=(3,), dtype=float32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor([20. 30. 40.], shape=(3,), dtype=float32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor([20. 30. 40.], shape=(3,), dtype=float32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(60.0, shape=(), dtype=float32)\n",
      "tf.Tensor(30.0, shape=(), dtype=float32)\n",
      "tf.Tensor([11. 21. 31.], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#1차원 배열 정의\n",
    "py_list = [10., 20., 30.] #파이썬 리스트\n",
    "num_arr = np.array([10.,10.,10.]) #넘파이 배열\n",
    "\n",
    "#텐서 변환(벡터)\n",
    "vec1 = tf.constant(py_list, dtype = tf.float32)\n",
    "vec2 = tf.constant(num_arr, dtype = tf.float32)\n",
    "\n",
    "print(vec1)\n",
    "print(vec2)\n",
    "print(tf.rank(vec1))\n",
    "print(tf.rank(vec2))\n",
    "\n",
    "add1 = tf.math.add(vec1,vec2) #다른 연산 함수도 전부 사용 가능\n",
    "print(add1)\n",
    "print(tf.rank(add1))\n",
    "\n",
    "add2 = vec1 + vec2 #다른 연산자도 전부 사용 가능\n",
    "print(add2)\n",
    "print(tf.rank(add2))\n",
    "\n",
    "print(tf.reduce_sum(vec1)) #벡터를 구성하는 모든 원소들의 합 계산\n",
    "print(tf.reduce_sum(vec2)) #벡터를 구성하는 모든 원소들의 합 계산\n",
    "\n",
    "print(vec1 + 1) #브로드캐스팅 연산\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[10 20]\n",
      " [30 40]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 1  0]\n",
      " [-1  2]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 10   0]\n",
      " [-30  80]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 30  60]\n",
      " [ 90 120]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[-10  40]\n",
      " [-10  80]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "<class 'numpy.ndarray'>\n",
      "[[-10  40]\n",
      " [-10  80]]\n"
     ]
    }
   ],
   "source": [
    "#2차원 배열 정의\n",
    "list_of_list = [[10,20],[30,40]]\n",
    "\n",
    "#텐서 변환(메트릭스)\n",
    "mat1 = tf.constant(list_of_list)\n",
    "\n",
    "print(mat1)\n",
    "print(tf.rank(mat1))\n",
    "\n",
    "#벡터 정의\n",
    "vec1 = tf.constant([1, 0])\n",
    "vec2 = tf.constant([-1, 2])\n",
    "\n",
    "#텐서 변환(메트릭스)_stack\n",
    "mat2 = tf.stack([vec1,vec2])\n",
    "\n",
    "print(mat2)\n",
    "print(tf.rank(mat2))\n",
    "\n",
    "#연산\n",
    "element_mul = tf.math.multiply(mat1,mat2)\n",
    "print(element_mul)\n",
    "print(tf.rank(element_mul))\n",
    "\n",
    "#연산_브로드 캐스팅\n",
    "element_bc = tf.math.multiply(mat1,3)\n",
    "print(element_bc)\n",
    "print(tf.rank(element_bc))\n",
    "\n",
    "#행렬곱 연산(선형대수)\n",
    "mat_mul = tf.matmul(mat1,mat2)\n",
    "print(mat_mul)\n",
    "print(tf.rank(mat_mul))\n",
    "\n",
    "#넘파이 배열로 변환\n",
    "np_arr = mat_mul.numpy()\n",
    "print(type(np_arr))\n",
    "print(np_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 1  2  3  4]\n",
      "  [ 5  6  7  8]]\n",
      "\n",
      " [[ 9 10 11 12]\n",
      "  [12 13 14 15]]\n",
      "\n",
      " [[16 17 18 20]\n",
      "  [21 22 23 24]]], shape=(3, 2, 4), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[ 1  2  3  4]\n",
      "  [ 5  6  7  8]]\n",
      "\n",
      " [[ 9 10 11 12]\n",
      "  [12 13 14 15]]\n",
      "\n",
      " [[16 17 18 20]\n",
      "  [21 22 23 24]]], shape=(3, 2, 4), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[ 1  2  3  4]\n",
      "  [ 5  6  7  8]]\n",
      "\n",
      " [[ 9 10 11 12]\n",
      "  [12 13 14 15]]\n",
      "\n",
      " [[16 17 18 20]\n",
      "  [21 22 23 24]]], shape=(3, 2, 4), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[[ 1  2  3  4]\n",
      "   [ 5  6  7  8]]\n",
      "\n",
      "  [[ 9 10 11 12]\n",
      "   [12 13 14 15]]\n",
      "\n",
      "  [[16 17 18 20]\n",
      "   [21 22 23 24]]]\n",
      "\n",
      "\n",
      " [[[ 1  2  3  4]\n",
      "   [ 5  6  7  8]]\n",
      "\n",
      "  [[ 9 10 11 12]\n",
      "   [12 13 14 15]]\n",
      "\n",
      "  [[16 17 18 20]\n",
      "   [21 22 23 24]]]\n",
      "\n",
      "\n",
      " [[[ 1  2  3  4]\n",
      "   [ 5  6  7  8]]\n",
      "\n",
      "  [[ 9 10 11 12]\n",
      "   [12 13 14 15]]\n",
      "\n",
      "  [[16 17 18 20]\n",
      "   [21 22 23 24]]]], shape=(3, 3, 2, 4), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#고차원 텐서\n",
    "\n",
    "#2차원 배열 정의\n",
    "mat1 = [[1,2,3,4],[5,6,7,8]]\n",
    "mat2 = [[9,10,11,12],[12,13,14,15]]\n",
    "mat3 = [[16,17,18,20],[21,22,23,24]]\n",
    "\n",
    "#텐서 변환(3차원 텐서)\n",
    "tensor1 = tf.constant([mat1,mat2,mat3])\n",
    "\n",
    "#랭크 확인\n",
    "print(tensor1)\n",
    "print(tf.rank(tensor1))\n",
    "\n",
    "#텐서 변환(3차원 텐서)_stack\n",
    "tensor2 = tf.stack([mat1,mat2,mat3])\n",
    "\n",
    "#랭크 확인\n",
    "print(tensor2)\n",
    "print(tf.rank(tensor2))\n",
    "\n",
    "vec1 = [1,2,3,4]\n",
    "vec2 = [5,6,7,8]\n",
    "vec3 = [9,10,11,12]\n",
    "vec4 = [12,13,14,15]\n",
    "vec5 = [16,17,18,20]\n",
    "vec6 = [21,22,23,24]\n",
    "\n",
    "arr = [[vec1,vec2],\n",
    "       [vec3,vec4],\n",
    "       [vec5,vec6]]\n",
    "\n",
    "tensor3 = tf.constant(arr)\n",
    "\n",
    "print(tensor3)\n",
    "print(tf.rank(tensor3))\n",
    "\n",
    "#랭크-4 텐서\n",
    "tensor4 = tf.stack([tensor1,tensor2,tensor3])\n",
    "print(tensor4)\n",
    "print(tf.rank(tensor4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([10 20 30 40 50], shape=(5,), dtype=int32)\n",
      "tf.Tensor(10, shape=(), dtype=int32)\n",
      "tf.Tensor(50, shape=(), dtype=int32)\n",
      "tf.Tensor([10 20 30], shape=(3,), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor([1 2 3 4], shape=(4,), dtype=int32)\n",
      "tf.Tensor([2 6], shape=(2,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[1 2 3 4]\n",
      " [5 6 7 8]], shape=(2, 4), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[ 1  2  3  4]\n",
      "  [ 5  6  7  8]]\n",
      "\n",
      " [[ 9 10 11 12]\n",
      "  [12 13 14 15]]\n",
      "\n",
      " [[16 17 18 20]\n",
      "  [21 22 23 24]]], shape=(3, 2, 4), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[1 2 3 4]\n",
      " [5 6 7 8]], shape=(2, 4), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[ 1  2]\n",
      "  [ 5  6]]\n",
      "\n",
      " [[ 9 10]\n",
      "  [12 13]]\n",
      "\n",
      " [[16 17]\n",
      "  [21 22]]], shape=(3, 2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#Tensor의 인덱싱\n",
    "vec = tf.constant([10,20,30,40,50])\n",
    "print(vec)\n",
    "print(vec[0])\n",
    "print(vec[-1])\n",
    "print(vec[:3])\n",
    "\n",
    "mat = tf.constant([[1,2,3,4],[5,6,7,8]])\n",
    "print(mat[0,2])\n",
    "print(mat[0,:])\n",
    "print(mat[:,1])\n",
    "print(mat[:,:])\n",
    "\n",
    "\n",
    "\n",
    "mat1 = [[1,2,3,4],[5,6,7,8]]\n",
    "mat2 = [[9,10,11,12],[12,13,14,15]]\n",
    "mat3 = [[16,17,18,20],[21,22,23,24]]\n",
    "tensor = tf.constant([mat1,mat2,mat3])\n",
    "print(tensor)\n",
    "print(tensor[0,:,:])\n",
    "print(tensor[:,:2,:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23], shape=(24,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[ 0  1]\n",
      "  [ 2  3]]\n",
      "\n",
      " [[ 4  5]\n",
      "  [ 6  7]]\n",
      "\n",
      " [[ 8  9]\n",
      "  [10 11]]\n",
      "\n",
      " [[12 13]\n",
      "  [14 15]]\n",
      "\n",
      " [[16 17]\n",
      "  [18 19]]\n",
      "\n",
      " [[20 21]\n",
      "  [22 23]]], shape=(6, 2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[ 0  1]\n",
      "  [ 2  3]\n",
      "  [ 4  5]\n",
      "  [ 6  7]]\n",
      "\n",
      " [[ 8  9]\n",
      "  [10 11]\n",
      "  [12 13]\n",
      "  [14 15]]\n",
      "\n",
      " [[16 17]\n",
      "  [18 19]\n",
      "  [20 21]\n",
      "  [22 23]]], shape=(3, 4, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[[ 0  1]\n",
      "   [ 2  3]]\n",
      "\n",
      "  [[ 4  5]\n",
      "   [ 6  7]]\n",
      "\n",
      "  [[ 8  9]\n",
      "   [10 11]]]\n",
      "\n",
      "\n",
      " [[[12 13]\n",
      "   [14 15]]\n",
      "\n",
      "  [[16 17]\n",
      "   [18 19]]\n",
      "\n",
      "  [[20 21]\n",
      "   [22 23]]]], shape=(2, 3, 2, 2), dtype=int32)\n",
      "tf.Tensor([ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23], shape=(24,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#Tensor의 형태 변환\n",
    "tensor = tf.constant(range(0,24))\n",
    "print(tensor)\n",
    "#→형태변환 실시\n",
    "tensor1 = tf.reshape(tensor, [-1,2,2,]) #-1을 넣는다는건 어떠한 수라도 상관이 없다는 뜻\n",
    "print(tensor1)\n",
    "\n",
    "tensor2 = tf.reshape(tensor1, [3,-1,2,]) #-1을 넣는다는건 어떠한 수라도 상관이 없다는 뜻\n",
    "print(tensor2)\n",
    "\n",
    "tensor3 = tf.reshape(tensor2, [2,3,-1,2,]) #-1을 넣는다는건 어떠한 수라도 상관이 없다는 뜻\n",
    "print(tensor3)\n",
    "\n",
    "tensor4 = tf.reshape(tensor3,[-1]) #다시 벡터 형태로 변경\n",
    "print(tensor4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0 1 2]\n",
      " [3 4 5]], shape=(2, 3), dtype=int32)\n",
      "<tf.Variable 'Variable:0' shape=(2, 3) dtype=int32, numpy=\n",
      "array([[0, 1, 2],\n",
      "       [3, 4, 5]])>\n",
      "이름 : Variable:0\n",
      "크기 : (2, 3)\n",
      "자료형 : <dtype: 'int32'>\n",
      "배열 : [[0 1 2]\n",
      " [3 4 5]]\n",
      "<tf.Variable 'Variable:0' shape=(2, 3) dtype=int32, numpy=\n",
      "array([[1, 1, 1],\n",
      "       [2, 2, 2]])>\n",
      "tf.Tensor(\n",
      "[[1 1 1]\n",
      " [2 2 2]], shape=(2, 3), dtype=int32)\n",
      "<tf.Variable 'New Name:0' shape=(2, 3) dtype=int32, numpy=\n",
      "array([[1, 1, 1],\n",
      "       [2, 2, 2]])>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[2, 2, 2],\n",
       "       [4, 4, 4]])>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#변수\n",
    "tensor1 = tf.constant([[0,1,2],[3,4,5]]) #메트릭스 선언\n",
    "print(tensor1)\n",
    "\n",
    "tensor_var1 = tf.Variable(tensor1) #변수 할당\n",
    "print(tensor_var1)\n",
    "\n",
    "print(\"이름 :\",tensor_var1.name)\n",
    "print(\"크기 :\",tensor_var1.shape)\n",
    "print(\"자료형 :\",tensor_var1.dtype)\n",
    "print(\"배열 :\",tensor_var1.numpy())\n",
    "\n",
    "tensor_var1.assign([[1,1,1],[2,2,2]]) #변수 재할당\n",
    "print(tensor_var1)\n",
    "\n",
    "tensor2 = tf.convert_to_tensor(tensor_var1) #변수를 텐서로 변환\n",
    "print(tensor2)\n",
    "\n",
    "tensor_var2 = tf.Variable(tensor2, name='New Name') #변수에 이름 할당\n",
    "print(tensor_var2)\n",
    "\n",
    "tensor_var1 + tensor_var2 #변수끼리 합산(단 출력물은 각 변수가 가지고 있는 텐서의 합으로 나타내므로 변수형태가 아닌 텐서로 나옴)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : [-0.20943771  1.2746525   1.213214   -0.17576952  1.876984    0.16379918\n",
      "  1.082245    0.6199966  -0.44402212  1.3048344 ]\n",
      "y : [-2.628313    1.8239574   1.6396422  -2.5273085   3.630952   -1.5086024\n",
      "  1.2467351  -0.14001012 -3.3320663   1.9145031 ]\n",
      "tf.Tensor(5.11122, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(4.555297, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(4.102832, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(3.7264862, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(3.4070325, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(3.1308815, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(2.8883655, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(2.6725478, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(2.478399, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(2.3022268, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(2.141275, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(1.9934533, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(1.8571408, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(1.7310549, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(1.6141573, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(1.5055892, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(1.4046257, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(1.3106416, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(1.2230909, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(1.1414891, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "EPOCH 20 - MSE : 1.1415 ----- a : 1.74 ------ b : -0.75\n",
      "tf.Tensor(1.0654008, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.9944326, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.92822516, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.8664486, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.80879956, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.7549972, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.7047815, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.657911, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.6141612, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.5733233, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.5352025, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.49961767, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.4663996, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.43539086, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.40644398, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.37942204, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.35419667, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.33064863, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.30866617, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.2881453, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "EPOCH 40 - MSE : 0.2881 ----- a : 2.37 ------ b : -1.37\n",
      "tf.Tensor(0.2689887, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.25110573, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.23441163, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.21882746, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.20427933, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.19069839, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.17802033, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.16618523, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.1551369, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.14482316, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.13519497, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.12620696, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.11781653, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.109983824, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.10267188, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.09584606, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.08947399, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.08352556, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.07797261, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.07278882, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "EPOCH 60 - MSE : 0.0728 ----- a : 2.69 ------ b : -1.68\n",
      "tf.Tensor(0.06794969, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.06343224, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.059215087, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.05527835, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.05160334, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.04817266, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.044970036, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.041980326, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.039189406, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.036584042, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.034151852, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.031881385, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.029761856, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.027783234, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.025936116, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.02421185, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.022602187, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.021099566, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.019696819, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.018387346, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "EPOCH 80 - MSE : 0.0184 ----- a : 2.84 ------ b : -1.84\n",
      "tf.Tensor(0.017164912, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.016023729, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.014958446, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.01396397, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.013035622, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.01216898, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.011359973, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.010604739, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.009899725, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.009241565, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.008627167, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.008053609, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.007518175, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.007018354, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0065517602, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.006116192, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0057095685, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0053299926, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.00497564, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.004644838, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "EPOCH 100 - MSE : 0.0046 ----- a : 2.92 ------ b : -1.92\n",
      "tf.Tensor(0.00433604, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.004047779, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.003778664, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0035274539, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0032929382, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0030740215, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0028696493, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0026788684, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.002500775, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0023345207, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0021793123, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0020344225, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0018991723, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0017729147, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0016550429, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0015450094, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0014422962, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0013464069, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0012568992, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0011733371, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "EPOCH 120 - MSE : 0.0012 ----- a : 2.96 ------ b : -1.96\n",
      "tf.Tensor(0.0010953353, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0010225122, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0009545331, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.00089107873, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0008318328, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.00077653246, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.00072490925, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0006767106, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0006317247, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0005897229, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0005505197, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.00051391876, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.00047975016, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0004478585, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.00041807978, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0003902872, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.00036434009, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0003401173, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.00031750533, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0002963942, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "EPOCH 140 - MSE : 0.0003 ----- a : 2.98 ------ b : -1.98\n",
      "tf.Tensor(0.00027669285, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.00025829676, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.00024112473, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0002250954, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.00021013214, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.00019616149, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.00018312043, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.00017094743, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.00015958307, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.00014897305, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0001390697, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.00012982478, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.00012119398, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.000113136965, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.00010561539, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(9.859293e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(9.2038375e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(8.591929e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(8.020784e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(7.4875294e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "EPOCH 160 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "tf.Tensor(6.989822e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(6.525243e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(6.0913582e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(5.6864792e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(5.3084244e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(4.9555576e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(4.626149e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(4.3186308e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(4.0315197e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(3.7634694e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(3.5133195e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(3.2796757e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(3.0617073e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(2.8582444e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(2.668137e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(2.4907591e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(2.325196e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(2.1706617e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(2.0262743e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(1.8916187e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "EPOCH 180 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "tf.Tensor(1.7658163e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(1.6484195e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(1.5388365e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(1.4365529e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(1.34104175e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(1.2519413e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(1.1686949e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(1.0910039e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(1.0184293e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(9.507528e-06, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(8.875337e-06, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(8.285768e-06, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(7.735149e-06, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(7.2203584e-06, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(6.740742e-06, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(6.2924387e-06, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(5.8736377e-06, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(5.483871e-06, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(5.1192337e-06, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(4.778576e-06, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "EPOCH 200 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n"
     ]
    }
   ],
   "source": [
    "#자동미분\n",
    "g = tf.random.Generator.from_seed(2020)\n",
    "x = g.normal(shape = (10,))\n",
    "y = 3*x-2\n",
    "\n",
    "print('x :',x.numpy())\n",
    "print('y :',y.numpy())\n",
    "\n",
    "#손실 함수 정의\n",
    "def cal_mse(x,y,a,b):\n",
    "    y_pred = a*x+b\n",
    "    squared_error = (y_pred - y)**2\n",
    "    mean_squared_error = tf.reduce_mean(squared_error)\n",
    "    return mean_squared_error\n",
    "\n",
    "\n",
    "a = tf.Variable(0.0)\n",
    "b = tf.Variable(0.0)\n",
    "\n",
    "EPOCHS = 200\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    with tf.GradientTape() as tape:\n",
    "        mse = cal_mse(x,y,a,b)\n",
    "    grad = tape.gradient(mse,{'a':a,'b':b})\n",
    "    d_a,d_b = grad['a'],grad['b']\n",
    "    \n",
    "    a.assign_sub(d_a*0.05)\n",
    "    b.assign_sub(d_b*0.05)\n",
    "    \n",
    "    if epoch%20 == 0:\n",
    "        print('EPOCH %d - MSE : %.4f ----- a : %.2f ------ b : %.2f'%(epoch, mse, a, b))\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : [-0.20943771  1.2746525   1.213214   -0.17576952  1.876984    0.16379918\n",
      "  1.082245    0.6199966  -0.44402212  1.3048344 ]\n",
      "y : [-2.628313    1.8239574   1.6396422  -2.5273085   3.630952   -1.5086024\n",
      "  1.2467351  -0.14001012 -3.3320663   1.9145031 ]\n",
      "1    EPOCH 1 - MSE : 5.1112 ----- a : 0.00 ------ b : 0.00\n",
      "2    EPOCH 1 - MSE : 5.1112 ----- a : 0.17 ------ b : 0.00\n",
      "1    EPOCH 2 - MSE : 4.5553 ----- a : 0.17 ------ b : 0.00\n",
      "2    EPOCH 2 - MSE : 4.5553 ----- a : 0.32 ------ b : -0.01\n",
      "1    EPOCH 3 - MSE : 4.1028 ----- a : 0.32 ------ b : -0.01\n",
      "2    EPOCH 3 - MSE : 4.1028 ----- a : 0.46 ------ b : -0.03\n",
      "1    EPOCH 4 - MSE : 3.7265 ----- a : 0.46 ------ b : -0.03\n",
      "2    EPOCH 4 - MSE : 3.7265 ----- a : 0.59 ------ b : -0.06\n",
      "1    EPOCH 5 - MSE : 3.4070 ----- a : 0.59 ------ b : -0.06\n",
      "2    EPOCH 5 - MSE : 3.4070 ----- a : 0.70 ------ b : -0.09\n",
      "1    EPOCH 6 - MSE : 3.1309 ----- a : 0.70 ------ b : -0.09\n",
      "2    EPOCH 6 - MSE : 3.1309 ----- a : 0.81 ------ b : -0.13\n",
      "1    EPOCH 7 - MSE : 2.8884 ----- a : 0.81 ------ b : -0.13\n",
      "2    EPOCH 7 - MSE : 2.8884 ----- a : 0.91 ------ b : -0.17\n",
      "1    EPOCH 8 - MSE : 2.6725 ----- a : 0.91 ------ b : -0.17\n",
      "2    EPOCH 8 - MSE : 2.6725 ----- a : 1.00 ------ b : -0.21\n",
      "1    EPOCH 9 - MSE : 2.4784 ----- a : 1.00 ------ b : -0.21\n",
      "2    EPOCH 9 - MSE : 2.4784 ----- a : 1.08 ------ b : -0.25\n",
      "1    EPOCH 10 - MSE : 2.3022 ----- a : 1.08 ------ b : -0.25\n",
      "2    EPOCH 10 - MSE : 2.3022 ----- a : 1.16 ------ b : -0.30\n",
      "1    EPOCH 11 - MSE : 2.1413 ----- a : 1.16 ------ b : -0.30\n",
      "2    EPOCH 11 - MSE : 2.1413 ----- a : 1.23 ------ b : -0.35\n",
      "1    EPOCH 12 - MSE : 1.9935 ----- a : 1.23 ------ b : -0.35\n",
      "2    EPOCH 12 - MSE : 1.9935 ----- a : 1.30 ------ b : -0.39\n",
      "1    EPOCH 13 - MSE : 1.8571 ----- a : 1.30 ------ b : -0.39\n",
      "2    EPOCH 13 - MSE : 1.8571 ----- a : 1.37 ------ b : -0.44\n",
      "1    EPOCH 14 - MSE : 1.7311 ----- a : 1.37 ------ b : -0.44\n",
      "2    EPOCH 14 - MSE : 1.7311 ----- a : 1.43 ------ b : -0.49\n",
      "1    EPOCH 15 - MSE : 1.6142 ----- a : 1.43 ------ b : -0.49\n",
      "2    EPOCH 15 - MSE : 1.6142 ----- a : 1.49 ------ b : -0.53\n",
      "1    EPOCH 16 - MSE : 1.5056 ----- a : 1.49 ------ b : -0.53\n",
      "2    EPOCH 16 - MSE : 1.5056 ----- a : 1.54 ------ b : -0.58\n",
      "1    EPOCH 17 - MSE : 1.4046 ----- a : 1.54 ------ b : -0.58\n",
      "2    EPOCH 17 - MSE : 1.4046 ----- a : 1.60 ------ b : -0.62\n",
      "1    EPOCH 18 - MSE : 1.3106 ----- a : 1.60 ------ b : -0.62\n",
      "2    EPOCH 18 - MSE : 1.3106 ----- a : 1.65 ------ b : -0.67\n",
      "1    EPOCH 19 - MSE : 1.2231 ----- a : 1.65 ------ b : -0.67\n",
      "2    EPOCH 19 - MSE : 1.2231 ----- a : 1.69 ------ b : -0.71\n",
      "1    EPOCH 20 - MSE : 1.1415 ----- a : 1.69 ------ b : -0.71\n",
      "2    EPOCH 20 - MSE : 1.1415 ----- a : 1.74 ------ b : -0.75\n",
      "1    EPOCH 21 - MSE : 1.0654 ----- a : 1.74 ------ b : -0.75\n",
      "2    EPOCH 21 - MSE : 1.0654 ----- a : 1.78 ------ b : -0.79\n",
      "1    EPOCH 22 - MSE : 0.9944 ----- a : 1.78 ------ b : -0.79\n",
      "2    EPOCH 22 - MSE : 0.9944 ----- a : 1.83 ------ b : -0.83\n",
      "1    EPOCH 23 - MSE : 0.9282 ----- a : 1.83 ------ b : -0.83\n",
      "2    EPOCH 23 - MSE : 0.9282 ----- a : 1.87 ------ b : -0.87\n",
      "1    EPOCH 24 - MSE : 0.8664 ----- a : 1.87 ------ b : -0.87\n",
      "2    EPOCH 24 - MSE : 0.8664 ----- a : 1.91 ------ b : -0.91\n",
      "1    EPOCH 25 - MSE : 0.8088 ----- a : 1.91 ------ b : -0.91\n",
      "2    EPOCH 25 - MSE : 0.8088 ----- a : 1.95 ------ b : -0.94\n",
      "1    EPOCH 26 - MSE : 0.7550 ----- a : 1.95 ------ b : -0.94\n",
      "2    EPOCH 26 - MSE : 0.7550 ----- a : 1.98 ------ b : -0.98\n",
      "1    EPOCH 27 - MSE : 0.7048 ----- a : 1.98 ------ b : -0.98\n",
      "2    EPOCH 27 - MSE : 0.7048 ----- a : 2.02 ------ b : -1.01\n",
      "1    EPOCH 28 - MSE : 0.6579 ----- a : 2.02 ------ b : -1.01\n",
      "2    EPOCH 28 - MSE : 0.6579 ----- a : 2.05 ------ b : -1.04\n",
      "1    EPOCH 29 - MSE : 0.6142 ----- a : 2.05 ------ b : -1.04\n",
      "2    EPOCH 29 - MSE : 0.6142 ----- a : 2.08 ------ b : -1.08\n",
      "1    EPOCH 30 - MSE : 0.5733 ----- a : 2.08 ------ b : -1.08\n",
      "2    EPOCH 30 - MSE : 0.5733 ----- a : 2.11 ------ b : -1.11\n",
      "1    EPOCH 31 - MSE : 0.5352 ----- a : 2.11 ------ b : -1.11\n",
      "2    EPOCH 31 - MSE : 0.5352 ----- a : 2.14 ------ b : -1.14\n",
      "1    EPOCH 32 - MSE : 0.4996 ----- a : 2.14 ------ b : -1.14\n",
      "2    EPOCH 32 - MSE : 0.4996 ----- a : 2.17 ------ b : -1.17\n",
      "1    EPOCH 33 - MSE : 0.4664 ----- a : 2.17 ------ b : -1.17\n",
      "2    EPOCH 33 - MSE : 0.4664 ----- a : 2.20 ------ b : -1.19\n",
      "1    EPOCH 34 - MSE : 0.4354 ----- a : 2.20 ------ b : -1.19\n",
      "2    EPOCH 34 - MSE : 0.4354 ----- a : 2.23 ------ b : -1.22\n",
      "1    EPOCH 35 - MSE : 0.4064 ----- a : 2.23 ------ b : -1.22\n",
      "2    EPOCH 35 - MSE : 0.4064 ----- a : 2.26 ------ b : -1.25\n",
      "1    EPOCH 36 - MSE : 0.3794 ----- a : 2.26 ------ b : -1.25\n",
      "2    EPOCH 36 - MSE : 0.3794 ----- a : 2.28 ------ b : -1.27\n",
      "1    EPOCH 37 - MSE : 0.3542 ----- a : 2.28 ------ b : -1.27\n",
      "2    EPOCH 37 - MSE : 0.3542 ----- a : 2.30 ------ b : -1.30\n",
      "1    EPOCH 38 - MSE : 0.3306 ----- a : 2.30 ------ b : -1.30\n",
      "2    EPOCH 38 - MSE : 0.3306 ----- a : 2.33 ------ b : -1.32\n",
      "1    EPOCH 39 - MSE : 0.3087 ----- a : 2.33 ------ b : -1.32\n",
      "2    EPOCH 39 - MSE : 0.3087 ----- a : 2.35 ------ b : -1.34\n",
      "1    EPOCH 40 - MSE : 0.2881 ----- a : 2.35 ------ b : -1.34\n",
      "2    EPOCH 40 - MSE : 0.2881 ----- a : 2.37 ------ b : -1.37\n",
      "1    EPOCH 41 - MSE : 0.2690 ----- a : 2.37 ------ b : -1.37\n",
      "2    EPOCH 41 - MSE : 0.2690 ----- a : 2.39 ------ b : -1.39\n",
      "1    EPOCH 42 - MSE : 0.2511 ----- a : 2.39 ------ b : -1.39\n",
      "2    EPOCH 42 - MSE : 0.2511 ----- a : 2.41 ------ b : -1.41\n",
      "1    EPOCH 43 - MSE : 0.2344 ----- a : 2.41 ------ b : -1.41\n",
      "2    EPOCH 43 - MSE : 0.2344 ----- a : 2.43 ------ b : -1.43\n",
      "1    EPOCH 44 - MSE : 0.2188 ----- a : 2.43 ------ b : -1.43\n",
      "2    EPOCH 44 - MSE : 0.2188 ----- a : 2.45 ------ b : -1.45\n",
      "1    EPOCH 45 - MSE : 0.2043 ----- a : 2.45 ------ b : -1.45\n",
      "2    EPOCH 45 - MSE : 0.2043 ----- a : 2.47 ------ b : -1.47\n",
      "1    EPOCH 46 - MSE : 0.1907 ----- a : 2.47 ------ b : -1.47\n",
      "2    EPOCH 46 - MSE : 0.1907 ----- a : 2.49 ------ b : -1.48\n",
      "1    EPOCH 47 - MSE : 0.1780 ----- a : 2.49 ------ b : -1.48\n",
      "2    EPOCH 47 - MSE : 0.1780 ----- a : 2.51 ------ b : -1.50\n",
      "1    EPOCH 48 - MSE : 0.1662 ----- a : 2.51 ------ b : -1.50\n",
      "2    EPOCH 48 - MSE : 0.1662 ----- a : 2.52 ------ b : -1.52\n",
      "1    EPOCH 49 - MSE : 0.1551 ----- a : 2.52 ------ b : -1.52\n",
      "2    EPOCH 49 - MSE : 0.1551 ----- a : 2.54 ------ b : -1.53\n",
      "1    EPOCH 50 - MSE : 0.1448 ----- a : 2.54 ------ b : -1.53\n",
      "2    EPOCH 50 - MSE : 0.1448 ----- a : 2.56 ------ b : -1.55\n",
      "1    EPOCH 51 - MSE : 0.1352 ----- a : 2.56 ------ b : -1.55\n",
      "2    EPOCH 51 - MSE : 0.1352 ----- a : 2.57 ------ b : -1.57\n",
      "1    EPOCH 52 - MSE : 0.1262 ----- a : 2.57 ------ b : -1.57\n",
      "2    EPOCH 52 - MSE : 0.1262 ----- a : 2.59 ------ b : -1.58\n",
      "1    EPOCH 53 - MSE : 0.1178 ----- a : 2.59 ------ b : -1.58\n",
      "2    EPOCH 53 - MSE : 0.1178 ----- a : 2.60 ------ b : -1.59\n",
      "1    EPOCH 54 - MSE : 0.1100 ----- a : 2.60 ------ b : -1.59\n",
      "2    EPOCH 54 - MSE : 0.1100 ----- a : 2.61 ------ b : -1.61\n",
      "1    EPOCH 55 - MSE : 0.1027 ----- a : 2.61 ------ b : -1.61\n",
      "2    EPOCH 55 - MSE : 0.1027 ----- a : 2.63 ------ b : -1.62\n",
      "1    EPOCH 56 - MSE : 0.0958 ----- a : 2.63 ------ b : -1.62\n",
      "2    EPOCH 56 - MSE : 0.0958 ----- a : 2.64 ------ b : -1.63\n",
      "1    EPOCH 57 - MSE : 0.0895 ----- a : 2.64 ------ b : -1.63\n",
      "2    EPOCH 57 - MSE : 0.0895 ----- a : 2.65 ------ b : -1.65\n",
      "1    EPOCH 58 - MSE : 0.0835 ----- a : 2.65 ------ b : -1.65\n",
      "2    EPOCH 58 - MSE : 0.0835 ----- a : 2.66 ------ b : -1.66\n",
      "1    EPOCH 59 - MSE : 0.0780 ----- a : 2.66 ------ b : -1.66\n",
      "2    EPOCH 59 - MSE : 0.0780 ----- a : 2.67 ------ b : -1.67\n",
      "1    EPOCH 60 - MSE : 0.0728 ----- a : 2.67 ------ b : -1.67\n",
      "2    EPOCH 60 - MSE : 0.0728 ----- a : 2.69 ------ b : -1.68\n",
      "1    EPOCH 61 - MSE : 0.0679 ----- a : 2.69 ------ b : -1.68\n",
      "2    EPOCH 61 - MSE : 0.0679 ----- a : 2.70 ------ b : -1.69\n",
      "1    EPOCH 62 - MSE : 0.0634 ----- a : 2.70 ------ b : -1.69\n",
      "2    EPOCH 62 - MSE : 0.0634 ----- a : 2.71 ------ b : -1.70\n",
      "1    EPOCH 63 - MSE : 0.0592 ----- a : 2.71 ------ b : -1.70\n",
      "2    EPOCH 63 - MSE : 0.0592 ----- a : 2.72 ------ b : -1.71\n",
      "1    EPOCH 64 - MSE : 0.0553 ----- a : 2.72 ------ b : -1.71\n",
      "2    EPOCH 64 - MSE : 0.0553 ----- a : 2.73 ------ b : -1.72\n",
      "1    EPOCH 65 - MSE : 0.0516 ----- a : 2.73 ------ b : -1.72\n",
      "2    EPOCH 65 - MSE : 0.0516 ----- a : 2.73 ------ b : -1.73\n",
      "1    EPOCH 66 - MSE : 0.0482 ----- a : 2.73 ------ b : -1.73\n",
      "2    EPOCH 66 - MSE : 0.0482 ----- a : 2.74 ------ b : -1.74\n",
      "1    EPOCH 67 - MSE : 0.0450 ----- a : 2.74 ------ b : -1.74\n",
      "2    EPOCH 67 - MSE : 0.0450 ----- a : 2.75 ------ b : -1.75\n",
      "1    EPOCH 68 - MSE : 0.0420 ----- a : 2.75 ------ b : -1.75\n",
      "2    EPOCH 68 - MSE : 0.0420 ----- a : 2.76 ------ b : -1.76\n",
      "1    EPOCH 69 - MSE : 0.0392 ----- a : 2.76 ------ b : -1.76\n",
      "2    EPOCH 69 - MSE : 0.0392 ----- a : 2.77 ------ b : -1.77\n",
      "1    EPOCH 70 - MSE : 0.0366 ----- a : 2.77 ------ b : -1.77\n",
      "2    EPOCH 70 - MSE : 0.0366 ----- a : 2.78 ------ b : -1.77\n",
      "1    EPOCH 71 - MSE : 0.0342 ----- a : 2.78 ------ b : -1.77\n",
      "2    EPOCH 71 - MSE : 0.0342 ----- a : 2.78 ------ b : -1.78\n",
      "1    EPOCH 72 - MSE : 0.0319 ----- a : 2.78 ------ b : -1.78\n",
      "2    EPOCH 72 - MSE : 0.0319 ----- a : 2.79 ------ b : -1.79\n",
      "1    EPOCH 73 - MSE : 0.0298 ----- a : 2.79 ------ b : -1.79\n",
      "2    EPOCH 73 - MSE : 0.0298 ----- a : 2.80 ------ b : -1.80\n",
      "1    EPOCH 74 - MSE : 0.0278 ----- a : 2.80 ------ b : -1.80\n",
      "2    EPOCH 74 - MSE : 0.0278 ----- a : 2.81 ------ b : -1.80\n",
      "1    EPOCH 75 - MSE : 0.0259 ----- a : 2.81 ------ b : -1.80\n",
      "2    EPOCH 75 - MSE : 0.0259 ----- a : 2.81 ------ b : -1.81\n",
      "1    EPOCH 76 - MSE : 0.0242 ----- a : 2.81 ------ b : -1.81\n",
      "2    EPOCH 76 - MSE : 0.0242 ----- a : 2.82 ------ b : -1.82\n",
      "1    EPOCH 77 - MSE : 0.0226 ----- a : 2.82 ------ b : -1.82\n",
      "2    EPOCH 77 - MSE : 0.0226 ----- a : 2.82 ------ b : -1.82\n",
      "1    EPOCH 78 - MSE : 0.0211 ----- a : 2.82 ------ b : -1.82\n",
      "2    EPOCH 78 - MSE : 0.0211 ----- a : 2.83 ------ b : -1.83\n",
      "1    EPOCH 79 - MSE : 0.0197 ----- a : 2.83 ------ b : -1.83\n",
      "2    EPOCH 79 - MSE : 0.0197 ----- a : 2.84 ------ b : -1.83\n",
      "1    EPOCH 80 - MSE : 0.0184 ----- a : 2.84 ------ b : -1.83\n",
      "2    EPOCH 80 - MSE : 0.0184 ----- a : 2.84 ------ b : -1.84\n",
      "1    EPOCH 81 - MSE : 0.0172 ----- a : 2.84 ------ b : -1.84\n",
      "2    EPOCH 81 - MSE : 0.0172 ----- a : 2.85 ------ b : -1.85\n",
      "1    EPOCH 82 - MSE : 0.0160 ----- a : 2.85 ------ b : -1.85\n",
      "2    EPOCH 82 - MSE : 0.0160 ----- a : 2.85 ------ b : -1.85\n",
      "1    EPOCH 83 - MSE : 0.0150 ----- a : 2.85 ------ b : -1.85\n",
      "2    EPOCH 83 - MSE : 0.0150 ----- a : 2.86 ------ b : -1.86\n",
      "1    EPOCH 84 - MSE : 0.0140 ----- a : 2.86 ------ b : -1.86\n",
      "2    EPOCH 84 - MSE : 0.0140 ----- a : 2.86 ------ b : -1.86\n",
      "1    EPOCH 85 - MSE : 0.0130 ----- a : 2.86 ------ b : -1.86\n",
      "2    EPOCH 85 - MSE : 0.0130 ----- a : 2.87 ------ b : -1.86\n",
      "1    EPOCH 86 - MSE : 0.0122 ----- a : 2.87 ------ b : -1.86\n",
      "2    EPOCH 86 - MSE : 0.0122 ----- a : 2.87 ------ b : -1.87\n",
      "1    EPOCH 87 - MSE : 0.0114 ----- a : 2.87 ------ b : -1.87\n",
      "2    EPOCH 87 - MSE : 0.0114 ----- a : 2.88 ------ b : -1.87\n",
      "1    EPOCH 88 - MSE : 0.0106 ----- a : 2.88 ------ b : -1.87\n",
      "2    EPOCH 88 - MSE : 0.0106 ----- a : 2.88 ------ b : -1.88\n",
      "1    EPOCH 89 - MSE : 0.0099 ----- a : 2.88 ------ b : -1.88\n",
      "2    EPOCH 89 - MSE : 0.0099 ----- a : 2.88 ------ b : -1.88\n",
      "1    EPOCH 90 - MSE : 0.0092 ----- a : 2.88 ------ b : -1.88\n",
      "2    EPOCH 90 - MSE : 0.0092 ----- a : 2.89 ------ b : -1.89\n",
      "1    EPOCH 91 - MSE : 0.0086 ----- a : 2.89 ------ b : -1.89\n",
      "2    EPOCH 91 - MSE : 0.0086 ----- a : 2.89 ------ b : -1.89\n",
      "1    EPOCH 92 - MSE : 0.0081 ----- a : 2.89 ------ b : -1.89\n",
      "2    EPOCH 92 - MSE : 0.0081 ----- a : 2.90 ------ b : -1.89\n",
      "1    EPOCH 93 - MSE : 0.0075 ----- a : 2.90 ------ b : -1.89\n",
      "2    EPOCH 93 - MSE : 0.0075 ----- a : 2.90 ------ b : -1.90\n",
      "1    EPOCH 94 - MSE : 0.0070 ----- a : 2.90 ------ b : -1.90\n",
      "2    EPOCH 94 - MSE : 0.0070 ----- a : 2.90 ------ b : -1.90\n",
      "1    EPOCH 95 - MSE : 0.0066 ----- a : 2.90 ------ b : -1.90\n",
      "2    EPOCH 95 - MSE : 0.0066 ----- a : 2.91 ------ b : -1.90\n",
      "1    EPOCH 96 - MSE : 0.0061 ----- a : 2.91 ------ b : -1.90\n",
      "2    EPOCH 96 - MSE : 0.0061 ----- a : 2.91 ------ b : -1.91\n",
      "1    EPOCH 97 - MSE : 0.0057 ----- a : 2.91 ------ b : -1.91\n",
      "2    EPOCH 97 - MSE : 0.0057 ----- a : 2.91 ------ b : -1.91\n",
      "1    EPOCH 98 - MSE : 0.0053 ----- a : 2.91 ------ b : -1.91\n",
      "2    EPOCH 98 - MSE : 0.0053 ----- a : 2.91 ------ b : -1.91\n",
      "1    EPOCH 99 - MSE : 0.0050 ----- a : 2.91 ------ b : -1.91\n",
      "2    EPOCH 99 - MSE : 0.0050 ----- a : 2.92 ------ b : -1.92\n",
      "1    EPOCH 100 - MSE : 0.0046 ----- a : 2.92 ------ b : -1.92\n",
      "2    EPOCH 100 - MSE : 0.0046 ----- a : 2.92 ------ b : -1.92\n",
      "1    EPOCH 101 - MSE : 0.0043 ----- a : 2.92 ------ b : -1.92\n",
      "2    EPOCH 101 - MSE : 0.0043 ----- a : 2.92 ------ b : -1.92\n",
      "1    EPOCH 102 - MSE : 0.0040 ----- a : 2.92 ------ b : -1.92\n",
      "2    EPOCH 102 - MSE : 0.0040 ----- a : 2.93 ------ b : -1.92\n",
      "1    EPOCH 103 - MSE : 0.0038 ----- a : 2.93 ------ b : -1.92\n",
      "2    EPOCH 103 - MSE : 0.0038 ----- a : 2.93 ------ b : -1.93\n",
      "1    EPOCH 104 - MSE : 0.0035 ----- a : 2.93 ------ b : -1.93\n",
      "2    EPOCH 104 - MSE : 0.0035 ----- a : 2.93 ------ b : -1.93\n",
      "1    EPOCH 105 - MSE : 0.0033 ----- a : 2.93 ------ b : -1.93\n",
      "2    EPOCH 105 - MSE : 0.0033 ----- a : 2.93 ------ b : -1.93\n",
      "1    EPOCH 106 - MSE : 0.0031 ----- a : 2.93 ------ b : -1.93\n",
      "2    EPOCH 106 - MSE : 0.0031 ----- a : 2.94 ------ b : -1.93\n",
      "1    EPOCH 107 - MSE : 0.0029 ----- a : 2.94 ------ b : -1.93\n",
      "2    EPOCH 107 - MSE : 0.0029 ----- a : 2.94 ------ b : -1.94\n",
      "1    EPOCH 108 - MSE : 0.0027 ----- a : 2.94 ------ b : -1.94\n",
      "2    EPOCH 108 - MSE : 0.0027 ----- a : 2.94 ------ b : -1.94\n",
      "1    EPOCH 109 - MSE : 0.0025 ----- a : 2.94 ------ b : -1.94\n",
      "2    EPOCH 109 - MSE : 0.0025 ----- a : 2.94 ------ b : -1.94\n",
      "1    EPOCH 110 - MSE : 0.0023 ----- a : 2.94 ------ b : -1.94\n",
      "2    EPOCH 110 - MSE : 0.0023 ----- a : 2.94 ------ b : -1.94\n",
      "1    EPOCH 111 - MSE : 0.0022 ----- a : 2.94 ------ b : -1.94\n",
      "2    EPOCH 111 - MSE : 0.0022 ----- a : 2.95 ------ b : -1.94\n",
      "1    EPOCH 112 - MSE : 0.0020 ----- a : 2.95 ------ b : -1.94\n",
      "2    EPOCH 112 - MSE : 0.0020 ----- a : 2.95 ------ b : -1.95\n",
      "1    EPOCH 113 - MSE : 0.0019 ----- a : 2.95 ------ b : -1.95\n",
      "2    EPOCH 113 - MSE : 0.0019 ----- a : 2.95 ------ b : -1.95\n",
      "1    EPOCH 114 - MSE : 0.0018 ----- a : 2.95 ------ b : -1.95\n",
      "2    EPOCH 114 - MSE : 0.0018 ----- a : 2.95 ------ b : -1.95\n",
      "1    EPOCH 115 - MSE : 0.0017 ----- a : 2.95 ------ b : -1.95\n",
      "2    EPOCH 115 - MSE : 0.0017 ----- a : 2.95 ------ b : -1.95\n",
      "1    EPOCH 116 - MSE : 0.0015 ----- a : 2.95 ------ b : -1.95\n",
      "2    EPOCH 116 - MSE : 0.0015 ----- a : 2.95 ------ b : -1.95\n",
      "1    EPOCH 117 - MSE : 0.0014 ----- a : 2.95 ------ b : -1.95\n",
      "2    EPOCH 117 - MSE : 0.0014 ----- a : 2.96 ------ b : -1.96\n",
      "1    EPOCH 118 - MSE : 0.0013 ----- a : 2.96 ------ b : -1.96\n",
      "2    EPOCH 118 - MSE : 0.0013 ----- a : 2.96 ------ b : -1.96\n",
      "1    EPOCH 119 - MSE : 0.0013 ----- a : 2.96 ------ b : -1.96\n",
      "2    EPOCH 119 - MSE : 0.0013 ----- a : 2.96 ------ b : -1.96\n",
      "1    EPOCH 120 - MSE : 0.0012 ----- a : 2.96 ------ b : -1.96\n",
      "2    EPOCH 120 - MSE : 0.0012 ----- a : 2.96 ------ b : -1.96\n",
      "1    EPOCH 121 - MSE : 0.0011 ----- a : 2.96 ------ b : -1.96\n",
      "2    EPOCH 121 - MSE : 0.0011 ----- a : 2.96 ------ b : -1.96\n",
      "1    EPOCH 122 - MSE : 0.0010 ----- a : 2.96 ------ b : -1.96\n",
      "2    EPOCH 122 - MSE : 0.0010 ----- a : 2.96 ------ b : -1.96\n",
      "1    EPOCH 123 - MSE : 0.0010 ----- a : 2.96 ------ b : -1.96\n",
      "2    EPOCH 123 - MSE : 0.0010 ----- a : 2.96 ------ b : -1.96\n",
      "1    EPOCH 124 - MSE : 0.0009 ----- a : 2.96 ------ b : -1.96\n",
      "2    EPOCH 124 - MSE : 0.0009 ----- a : 2.97 ------ b : -1.96\n",
      "1    EPOCH 125 - MSE : 0.0008 ----- a : 2.97 ------ b : -1.96\n",
      "2    EPOCH 125 - MSE : 0.0008 ----- a : 2.97 ------ b : -1.97\n",
      "1    EPOCH 126 - MSE : 0.0008 ----- a : 2.97 ------ b : -1.97\n",
      "2    EPOCH 126 - MSE : 0.0008 ----- a : 2.97 ------ b : -1.97\n",
      "1    EPOCH 127 - MSE : 0.0007 ----- a : 2.97 ------ b : -1.97\n",
      "2    EPOCH 127 - MSE : 0.0007 ----- a : 2.97 ------ b : -1.97\n",
      "1    EPOCH 128 - MSE : 0.0007 ----- a : 2.97 ------ b : -1.97\n",
      "2    EPOCH 128 - MSE : 0.0007 ----- a : 2.97 ------ b : -1.97\n",
      "1    EPOCH 129 - MSE : 0.0006 ----- a : 2.97 ------ b : -1.97\n",
      "2    EPOCH 129 - MSE : 0.0006 ----- a : 2.97 ------ b : -1.97\n",
      "1    EPOCH 130 - MSE : 0.0006 ----- a : 2.97 ------ b : -1.97\n",
      "2    EPOCH 130 - MSE : 0.0006 ----- a : 2.97 ------ b : -1.97\n",
      "1    EPOCH 131 - MSE : 0.0006 ----- a : 2.97 ------ b : -1.97\n",
      "2    EPOCH 131 - MSE : 0.0006 ----- a : 2.97 ------ b : -1.97\n",
      "1    EPOCH 132 - MSE : 0.0005 ----- a : 2.97 ------ b : -1.97\n",
      "2    EPOCH 132 - MSE : 0.0005 ----- a : 2.97 ------ b : -1.97\n",
      "1    EPOCH 133 - MSE : 0.0005 ----- a : 2.97 ------ b : -1.97\n",
      "2    EPOCH 133 - MSE : 0.0005 ----- a : 2.97 ------ b : -1.97\n",
      "1    EPOCH 134 - MSE : 0.0004 ----- a : 2.97 ------ b : -1.97\n",
      "2    EPOCH 134 - MSE : 0.0004 ----- a : 2.98 ------ b : -1.97\n",
      "1    EPOCH 135 - MSE : 0.0004 ----- a : 2.98 ------ b : -1.97\n",
      "2    EPOCH 135 - MSE : 0.0004 ----- a : 2.98 ------ b : -1.98\n",
      "1    EPOCH 136 - MSE : 0.0004 ----- a : 2.98 ------ b : -1.98\n",
      "2    EPOCH 136 - MSE : 0.0004 ----- a : 2.98 ------ b : -1.98\n",
      "1    EPOCH 137 - MSE : 0.0004 ----- a : 2.98 ------ b : -1.98\n",
      "2    EPOCH 137 - MSE : 0.0004 ----- a : 2.98 ------ b : -1.98\n",
      "1    EPOCH 138 - MSE : 0.0003 ----- a : 2.98 ------ b : -1.98\n",
      "2    EPOCH 138 - MSE : 0.0003 ----- a : 2.98 ------ b : -1.98\n",
      "1    EPOCH 139 - MSE : 0.0003 ----- a : 2.98 ------ b : -1.98\n",
      "2    EPOCH 139 - MSE : 0.0003 ----- a : 2.98 ------ b : -1.98\n",
      "1    EPOCH 140 - MSE : 0.0003 ----- a : 2.98 ------ b : -1.98\n",
      "2    EPOCH 140 - MSE : 0.0003 ----- a : 2.98 ------ b : -1.98\n",
      "1    EPOCH 141 - MSE : 0.0003 ----- a : 2.98 ------ b : -1.98\n",
      "2    EPOCH 141 - MSE : 0.0003 ----- a : 2.98 ------ b : -1.98\n",
      "1    EPOCH 142 - MSE : 0.0003 ----- a : 2.98 ------ b : -1.98\n",
      "2    EPOCH 142 - MSE : 0.0003 ----- a : 2.98 ------ b : -1.98\n",
      "1    EPOCH 143 - MSE : 0.0002 ----- a : 2.98 ------ b : -1.98\n",
      "2    EPOCH 143 - MSE : 0.0002 ----- a : 2.98 ------ b : -1.98\n",
      "1    EPOCH 144 - MSE : 0.0002 ----- a : 2.98 ------ b : -1.98\n",
      "2    EPOCH 144 - MSE : 0.0002 ----- a : 2.98 ------ b : -1.98\n",
      "1    EPOCH 145 - MSE : 0.0002 ----- a : 2.98 ------ b : -1.98\n",
      "2    EPOCH 145 - MSE : 0.0002 ----- a : 2.98 ------ b : -1.98\n",
      "1    EPOCH 146 - MSE : 0.0002 ----- a : 2.98 ------ b : -1.98\n",
      "2    EPOCH 146 - MSE : 0.0002 ----- a : 2.98 ------ b : -1.98\n",
      "1    EPOCH 147 - MSE : 0.0002 ----- a : 2.98 ------ b : -1.98\n",
      "2    EPOCH 147 - MSE : 0.0002 ----- a : 2.98 ------ b : -1.98\n",
      "1    EPOCH 148 - MSE : 0.0002 ----- a : 2.98 ------ b : -1.98\n",
      "2    EPOCH 148 - MSE : 0.0002 ----- a : 2.98 ------ b : -1.98\n",
      "1    EPOCH 149 - MSE : 0.0002 ----- a : 2.98 ------ b : -1.98\n",
      "2    EPOCH 149 - MSE : 0.0002 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 150 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 150 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 151 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 151 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 152 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 152 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 153 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 153 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 154 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 154 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 155 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 155 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 156 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 156 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 157 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 157 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 158 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 158 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 159 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 159 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 160 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 160 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 161 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 161 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 162 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 162 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 163 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 163 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 164 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 164 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 165 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 165 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 166 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 166 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 167 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 167 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 168 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 168 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 169 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 169 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 170 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 170 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 171 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 171 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 172 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 172 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 173 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 173 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 174 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 174 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 175 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 175 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 176 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 176 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 177 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 177 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 178 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 178 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 179 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 179 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 180 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 180 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 181 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 181 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "1    EPOCH 182 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "2    EPOCH 182 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "1    EPOCH 183 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "2    EPOCH 183 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "1    EPOCH 184 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "2    EPOCH 184 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "1    EPOCH 185 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "2    EPOCH 185 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "1    EPOCH 186 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "2    EPOCH 186 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "1    EPOCH 187 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "2    EPOCH 187 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "1    EPOCH 188 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "2    EPOCH 188 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "1    EPOCH 189 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "2    EPOCH 189 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "1    EPOCH 190 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "2    EPOCH 190 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "1    EPOCH 191 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "2    EPOCH 191 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "1    EPOCH 192 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "2    EPOCH 192 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "1    EPOCH 193 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "2    EPOCH 193 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "1    EPOCH 194 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "2    EPOCH 194 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "1    EPOCH 195 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "2    EPOCH 195 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "1    EPOCH 196 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "2    EPOCH 196 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "1    EPOCH 197 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "2    EPOCH 197 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "1    EPOCH 198 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "2    EPOCH 198 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "1    EPOCH 199 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "2    EPOCH 199 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "1    EPOCH 200 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "2    EPOCH 200 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n"
     ]
    }
   ],
   "source": [
    "#자동미분\n",
    "g = tf.random.Generator.from_seed(2020)\n",
    "x = g.normal(shape = (10,))\n",
    "y = 3*x-2\n",
    "\n",
    "print('x :',x.numpy())\n",
    "print('y :',y.numpy())\n",
    "\n",
    "#손실 함수 정의\n",
    "def cal_mse(x,y,a,b):\n",
    "    y_pred = a*x+b\n",
    "    squared_error = (y_pred - y)**2\n",
    "    mean_squared_error = tf.reduce_mean(squared_error)\n",
    "    return mean_squared_error\n",
    "\n",
    "\n",
    "a = tf.Variable(0.0)\n",
    "b = tf.Variable(0.0)\n",
    "\n",
    "EPOCHS = 200\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    with tf.GradientTape() as tape:\n",
    "        mse = cal_mse(x,y,a,b)\n",
    "    grad = tape.gradient(mse,{'a':a,'b':b})\n",
    "    d_a,d_b = grad['a'],grad['b']\n",
    "    print('1    EPOCH %d - MSE : %.4f ----- a : %.2f ------ b : %.2f'%(epoch, mse, a, b))\n",
    "    \n",
    "    a.assign_sub(d_a*0.05)\n",
    "    b.assign_sub(d_b*0.05)\n",
    "\n",
    "    print('2    EPOCH %d - MSE : %.4f ----- a : %.2f ------ b : %.2f'%(epoch, mse, a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:0.3,b:0.5\n",
      " 0     w = 0.16850, b = 0.70051     error = 6.47932\n",
      " 5     w = 0.14615, b = 0.58492     error = 0.12124\n",
      "10     w = 0.17203, b = 0.56988     error = 0.08295\n",
      "15     w = 0.19365, b = 0.55795     error = 0.05703\n",
      "20     w = 0.21149, b = 0.54810     error = 0.03938\n",
      "25     w = 0.22621, b = 0.53998     error = 0.02737\n",
      "30     w = 0.23835, b = 0.53328     error = 0.01919\n",
      "35     w = 0.24838, b = 0.52775     error = 0.01362\n",
      "40     w = 0.25665, b = 0.52319     error = 0.00983\n",
      "45     w = 0.26347, b = 0.51942     error = 0.00725\n",
      "50     w = 0.26910, b = 0.51632     error = 0.00549\n",
      "------------------------------------------------------------\n",
      "52     w = 0.3, b = 0.5     error = 0.00495\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#경사하강법 실습\n",
    "\n",
    "#샘플에 활용할 데이터 셋 만들기\n",
    "def make_linear(w, b, size,noise):\n",
    "    x = np.random.rand(size)\n",
    "    y = w*x+b\n",
    "    noise = np.random.uniform(-abs(noise),abs(noise),size = y.shape)\n",
    "    yy = y + noise\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot(x,y,color='r',label=f'y={w}*x+{b}')\n",
    "    plt.scatter(x,yy,label ='data')\n",
    "    plt.legend(fontsize=20)\n",
    "    plt.show()\n",
    "    print(f'w:{w},b:{b}')\n",
    "    return x,yy\n",
    "\n",
    "x,y = make_linear(w=0.3,b=0.5,size=100,noise=0.01)\n",
    "\n",
    "#최대 반복 횟수\n",
    "num_epoch = 100\n",
    "\n",
    "#학습률(learnig_rate)\n",
    "learning_rate = 0.005\n",
    "\n",
    "#에러기록\n",
    "errors = []\n",
    "\n",
    "#random 한 값으로 w,b를 초기화\n",
    "w = np.random.uniform(low = 0.0, high = 1.0)\n",
    "b = np.random.uniform(low = 0.0, high = 1.0)\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    #Hypothesis 정의\n",
    "    y_hat = w*x+b\n",
    "    \n",
    "    #Loss Function 정의\n",
    "    error = 0.5*((y_hat - y)**2).sum()\n",
    "    if error < 0.005:\n",
    "        break\n",
    "    #Gradient 미분 계산\n",
    "    w = w - learning_rate*((y_hat - y)*x).sum()\n",
    "    b = b - learning_rate*(y_hat -y).sum()\n",
    "    \n",
    "    errors.append(error)\n",
    "    \n",
    "    if epoch%5 == 0:\n",
    "        print(\"{0:2}     w = {1:.5f}, b = {2:.5f}     error = {3:.5f}\".format(epoch, w, b, error))\n",
    "\n",
    "print(\"----\" * 15)\n",
    "print(\"{0:2}     w = {1:.1f}, b = {2:.1f}     error = {3:.5f}\".format(epoch, w, b, error))\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "plt.plot(errors)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Error')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.core.dense.Dense at 0x242a41fddf0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "#10개의 노드(뉴런)으로 이루어진 Dense 레이어\n",
    "tf.keras.layers.Dense(10)\n",
    "#ReLU 활성화 함수 적용\n",
    "tf.keras.layers.Dense(10, activation ='relu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#샘플 데이터셋 생성\n",
    "x = np.arange(1,6)\n",
    "\n",
    "#y = 3x + 2\n",
    "y=3*x+2\n",
    "\n",
    "#시각화\n",
    "plt.plot(x,y)\n",
    "plt.title('y=3x+2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델의 구조를 생성하는 방법\n",
    "import tensorflow as tf\n",
    "\n",
    "#리스트 형\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10),\n",
    "    tf.keras.layers.Dense(5),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])\n",
    "\n",
    "#add 함수로 레이어 추가\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(10))\n",
    "model.add(tf.keras.layers.Dense(5))\n",
    "model.add(tf.keras.layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#입력 데이터의 형태\n",
    "import tensorflow as tf\n",
    "model = tf.keras.Sequential([\n",
    "    #입력 데이터의 shape=(150,4)인 경우 input_shape 지정\n",
    "    #150, 4의 의미는 4개의 컬럼을 가진 150 row의 데이터 메트릭스를 의미한다\n",
    "    tf.keras.layers.Dense(10, input_shape = [4]),\n",
    "    tf.keras.layers.Dense(5),\n",
    "    tf.keras.layers.Dense(1),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_26 (Dense)            (None, 1)                 2         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2\n",
      "Trainable params: 2\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#단순선형회귀 모델의 정의\n",
    "import tensorflow as tf\n",
    "model = tf.keras.Sequential([\n",
    "    #y=wx+b에서 입력 데이터(컬럼)은 x한개기 때문에 input_shape는 1로 셋팅\n",
    "    #1개의 뉴런을 가지는 Dense레이어는 1개의 출력 값을 가지므로, 출력값은 y에 대한 모델의 예측 값이다\n",
    "    tf.keras.layers.Dense(1, input_shape = [1])\n",
    "])\n",
    "\n",
    "#모델 요약\n",
    "model.summary()\n",
    "\n",
    "# Total params: 6 → 해당 모델의 총 파라미터가 6개다\n",
    "# Trainable params: 2 → 모델 훈련 시 업데이트할 파라미터의 총 개수\n",
    "# Non-trainable params: 0 → 훈련 시 업데이트하지 않을 파라미터의 총 개수\n",
    "# 해당 모델에서는 업데이트 파라미터가 가중치 w와 편향 b 두개라서 총 파라미터가 2개다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "931e65fb8f6b94005bf1e95e6550bb9bf9f82953a045b69934725ecc774a59a6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
