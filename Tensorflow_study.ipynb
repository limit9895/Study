{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(1.0, shape=(), dtype=float32)\n",
      "tf.Tensor(2.0, shape=(), dtype=float32)\n",
      "tf.Tensor(3.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n",
      "tf.Tensor(9.0, shape=(), dtype=float32)\n",
      "tf.Tensor(0, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#스칼라 정의\n",
    "a = tf.constant(1)\n",
    "b = tf.constant(2)\n",
    "print(a)\n",
    "print(b)\n",
    "print(tf.rank(a)) #차원 확인\n",
    "a = tf.cast(a,tf.float32)\n",
    "b = tf.cast(b,tf.float32)\n",
    "print(a)\n",
    "print(b)\n",
    "#계산 : add(덧셈), subtract(뺄셈), multiply(곱셈), divide(나눗셈), mod(나눗셈_나머지), floordiv(나눗셈_몫),square(거듭제곱),sqrt(제곱근),\n",
    "c = tf.math.add(a,b)\n",
    "d = tf.math.square(c)\n",
    "print(c)\n",
    "print(tf.rank(c)) #차원 확인\n",
    "print(d)\n",
    "print(tf.rank(d)) #차원 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([10. 20. 30.], shape=(3,), dtype=float32)\n",
      "tf.Tensor([10. 10. 10.], shape=(3,), dtype=float32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor([20. 30. 40.], shape=(3,), dtype=float32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor([20. 30. 40.], shape=(3,), dtype=float32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor(60.0, shape=(), dtype=float32)\n",
      "tf.Tensor(30.0, shape=(), dtype=float32)\n",
      "tf.Tensor([11. 21. 31.], shape=(3,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#1차원 배열 정의\n",
    "py_list = [10., 20., 30.] #파이썬 리스트\n",
    "num_arr = np.array([10.,10.,10.]) #넘파이 배열\n",
    "\n",
    "#텐서 변환(벡터)\n",
    "vec1 = tf.constant(py_list, dtype = tf.float32)\n",
    "vec2 = tf.constant(num_arr, dtype = tf.float32)\n",
    "\n",
    "print(vec1)\n",
    "print(vec2)\n",
    "print(tf.rank(vec1))\n",
    "print(tf.rank(vec2))\n",
    "\n",
    "add1 = tf.math.add(vec1,vec2) #다른 연산 함수도 전부 사용 가능\n",
    "print(add1)\n",
    "print(tf.rank(add1))\n",
    "\n",
    "add2 = vec1 + vec2 #다른 연산자도 전부 사용 가능\n",
    "print(add2)\n",
    "print(tf.rank(add2))\n",
    "\n",
    "print(tf.reduce_sum(vec1)) #벡터를 구성하는 모든 원소들의 합 계산\n",
    "print(tf.reduce_sum(vec2)) #벡터를 구성하는 모든 원소들의 합 계산\n",
    "\n",
    "print(vec1 + 1) #브로드캐스팅 연산\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[10 20]\n",
      " [30 40]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 1  0]\n",
      " [-1  2]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 10   0]\n",
      " [-30  80]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 30  60]\n",
      " [ 90 120]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[-10  40]\n",
      " [-10  80]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "<class 'numpy.ndarray'>\n",
      "[[-10  40]\n",
      " [-10  80]]\n"
     ]
    }
   ],
   "source": [
    "#2차원 배열 정의\n",
    "list_of_list = [[10,20],[30,40]]\n",
    "\n",
    "#텐서 변환(메트릭스)\n",
    "mat1 = tf.constant(list_of_list)\n",
    "\n",
    "print(mat1)\n",
    "print(tf.rank(mat1))\n",
    "\n",
    "#벡터 정의\n",
    "vec1 = tf.constant([1, 0])\n",
    "vec2 = tf.constant([-1, 2])\n",
    "\n",
    "#텐서 변환(메트릭스)_stack\n",
    "mat2 = tf.stack([vec1,vec2])\n",
    "\n",
    "print(mat2)\n",
    "print(tf.rank(mat2))\n",
    "\n",
    "#연산\n",
    "element_mul = tf.math.multiply(mat1,mat2)\n",
    "print(element_mul)\n",
    "print(tf.rank(element_mul))\n",
    "\n",
    "#연산_브로드 캐스팅\n",
    "element_bc = tf.math.multiply(mat1,3)\n",
    "print(element_bc)\n",
    "print(tf.rank(element_bc))\n",
    "\n",
    "#행렬곱 연산(선형대수)\n",
    "mat_mul = tf.matmul(mat1,mat2)\n",
    "print(mat_mul)\n",
    "print(tf.rank(mat_mul))\n",
    "\n",
    "#넘파이 배열로 변환\n",
    "np_arr = mat_mul.numpy()\n",
    "print(type(np_arr))\n",
    "print(np_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 1  2  3  4]\n",
      "  [ 5  6  7  8]]\n",
      "\n",
      " [[ 9 10 11 12]\n",
      "  [12 13 14 15]]\n",
      "\n",
      " [[16 17 18 20]\n",
      "  [21 22 23 24]]], shape=(3, 2, 4), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[ 1  2  3  4]\n",
      "  [ 5  6  7  8]]\n",
      "\n",
      " [[ 9 10 11 12]\n",
      "  [12 13 14 15]]\n",
      "\n",
      " [[16 17 18 20]\n",
      "  [21 22 23 24]]], shape=(3, 2, 4), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[ 1  2  3  4]\n",
      "  [ 5  6  7  8]]\n",
      "\n",
      " [[ 9 10 11 12]\n",
      "  [12 13 14 15]]\n",
      "\n",
      " [[16 17 18 20]\n",
      "  [21 22 23 24]]], shape=(3, 2, 4), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[[ 1  2  3  4]\n",
      "   [ 5  6  7  8]]\n",
      "\n",
      "  [[ 9 10 11 12]\n",
      "   [12 13 14 15]]\n",
      "\n",
      "  [[16 17 18 20]\n",
      "   [21 22 23 24]]]\n",
      "\n",
      "\n",
      " [[[ 1  2  3  4]\n",
      "   [ 5  6  7  8]]\n",
      "\n",
      "  [[ 9 10 11 12]\n",
      "   [12 13 14 15]]\n",
      "\n",
      "  [[16 17 18 20]\n",
      "   [21 22 23 24]]]\n",
      "\n",
      "\n",
      " [[[ 1  2  3  4]\n",
      "   [ 5  6  7  8]]\n",
      "\n",
      "  [[ 9 10 11 12]\n",
      "   [12 13 14 15]]\n",
      "\n",
      "  [[16 17 18 20]\n",
      "   [21 22 23 24]]]], shape=(3, 3, 2, 4), dtype=int32)\n",
      "tf.Tensor(4, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#고차원 텐서\n",
    "\n",
    "#2차원 배열 정의\n",
    "mat1 = [[1,2,3,4],[5,6,7,8]]\n",
    "mat2 = [[9,10,11,12],[12,13,14,15]]\n",
    "mat3 = [[16,17,18,20],[21,22,23,24]]\n",
    "\n",
    "#텐서 변환(3차원 텐서)\n",
    "tensor1 = tf.constant([mat1,mat2,mat3])\n",
    "\n",
    "#랭크 확인\n",
    "print(tensor1)\n",
    "print(tf.rank(tensor1))\n",
    "\n",
    "#텐서 변환(3차원 텐서)_stack\n",
    "tensor2 = tf.stack([mat1,mat2,mat3])\n",
    "\n",
    "#랭크 확인\n",
    "print(tensor2)\n",
    "print(tf.rank(tensor2))\n",
    "\n",
    "vec1 = [1,2,3,4]\n",
    "vec2 = [5,6,7,8]\n",
    "vec3 = [9,10,11,12]\n",
    "vec4 = [12,13,14,15]\n",
    "vec5 = [16,17,18,20]\n",
    "vec6 = [21,22,23,24]\n",
    "\n",
    "arr = [[vec1,vec2],\n",
    "       [vec3,vec4],\n",
    "       [vec5,vec6]]\n",
    "\n",
    "tensor3 = tf.constant(arr)\n",
    "\n",
    "print(tensor3)\n",
    "print(tf.rank(tensor3))\n",
    "\n",
    "#랭크-4 텐서\n",
    "tensor4 = tf.stack([tensor1,tensor2,tensor3])\n",
    "print(tensor4)\n",
    "print(tf.rank(tensor4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([10 20 30 40 50], shape=(5,), dtype=int32)\n",
      "tf.Tensor(10, shape=(), dtype=int32)\n",
      "tf.Tensor(50, shape=(), dtype=int32)\n",
      "tf.Tensor([10 20 30], shape=(3,), dtype=int32)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor([1 2 3 4], shape=(4,), dtype=int32)\n",
      "tf.Tensor([2 6], shape=(2,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[1 2 3 4]\n",
      " [5 6 7 8]], shape=(2, 4), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[ 1  2  3  4]\n",
      "  [ 5  6  7  8]]\n",
      "\n",
      " [[ 9 10 11 12]\n",
      "  [12 13 14 15]]\n",
      "\n",
      " [[16 17 18 20]\n",
      "  [21 22 23 24]]], shape=(3, 2, 4), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[1 2 3 4]\n",
      " [5 6 7 8]], shape=(2, 4), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[ 1  2]\n",
      "  [ 5  6]]\n",
      "\n",
      " [[ 9 10]\n",
      "  [12 13]]\n",
      "\n",
      " [[16 17]\n",
      "  [21 22]]], shape=(3, 2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#Tensor의 인덱싱\n",
    "vec = tf.constant([10,20,30,40,50])\n",
    "print(vec)\n",
    "print(vec[0])\n",
    "print(vec[-1])\n",
    "print(vec[:3])\n",
    "\n",
    "mat = tf.constant([[1,2,3,4],[5,6,7,8]])\n",
    "print(mat[0,2])\n",
    "print(mat[0,:])\n",
    "print(mat[:,1])\n",
    "print(mat[:,:])\n",
    "\n",
    "\n",
    "\n",
    "mat1 = [[1,2,3,4],[5,6,7,8]]\n",
    "mat2 = [[9,10,11,12],[12,13,14,15]]\n",
    "mat3 = [[16,17,18,20],[21,22,23,24]]\n",
    "tensor = tf.constant([mat1,mat2,mat3])\n",
    "print(tensor)\n",
    "print(tensor[0,:,:])\n",
    "print(tensor[:,:2,:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23], shape=(24,), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[ 0  1]\n",
      "  [ 2  3]]\n",
      "\n",
      " [[ 4  5]\n",
      "  [ 6  7]]\n",
      "\n",
      " [[ 8  9]\n",
      "  [10 11]]\n",
      "\n",
      " [[12 13]\n",
      "  [14 15]]\n",
      "\n",
      " [[16 17]\n",
      "  [18 19]]\n",
      "\n",
      " [[20 21]\n",
      "  [22 23]]], shape=(6, 2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[ 0  1]\n",
      "  [ 2  3]\n",
      "  [ 4  5]\n",
      "  [ 6  7]]\n",
      "\n",
      " [[ 8  9]\n",
      "  [10 11]\n",
      "  [12 13]\n",
      "  [14 15]]\n",
      "\n",
      " [[16 17]\n",
      "  [18 19]\n",
      "  [20 21]\n",
      "  [22 23]]], shape=(3, 4, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[[[ 0  1]\n",
      "   [ 2  3]]\n",
      "\n",
      "  [[ 4  5]\n",
      "   [ 6  7]]\n",
      "\n",
      "  [[ 8  9]\n",
      "   [10 11]]]\n",
      "\n",
      "\n",
      " [[[12 13]\n",
      "   [14 15]]\n",
      "\n",
      "  [[16 17]\n",
      "   [18 19]]\n",
      "\n",
      "  [[20 21]\n",
      "   [22 23]]]], shape=(2, 3, 2, 2), dtype=int32)\n",
      "tf.Tensor([ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23], shape=(24,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "#Tensor의 형태 변환\n",
    "tensor = tf.constant(range(0,24))\n",
    "print(tensor)\n",
    "#→형태변환 실시\n",
    "tensor1 = tf.reshape(tensor, [-1,2,2,]) #-1을 넣는다는건 어떠한 수라도 상관이 없다는 뜻\n",
    "print(tensor1)\n",
    "\n",
    "tensor2 = tf.reshape(tensor1, [3,-1,2,]) #-1을 넣는다는건 어떠한 수라도 상관이 없다는 뜻\n",
    "print(tensor2)\n",
    "\n",
    "tensor3 = tf.reshape(tensor2, [2,3,-1,2,]) #-1을 넣는다는건 어떠한 수라도 상관이 없다는 뜻\n",
    "print(tensor3)\n",
    "\n",
    "tensor4 = tf.reshape(tensor3,[-1]) #다시 벡터 형태로 변경\n",
    "print(tensor4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0 1 2]\n",
      " [3 4 5]], shape=(2, 3), dtype=int32)\n",
      "<tf.Variable 'Variable:0' shape=(2, 3) dtype=int32, numpy=\n",
      "array([[0, 1, 2],\n",
      "       [3, 4, 5]])>\n",
      "이름 : Variable:0\n",
      "크기 : (2, 3)\n",
      "자료형 : <dtype: 'int32'>\n",
      "배열 : [[0 1 2]\n",
      " [3 4 5]]\n",
      "<tf.Variable 'Variable:0' shape=(2, 3) dtype=int32, numpy=\n",
      "array([[1, 1, 1],\n",
      "       [2, 2, 2]])>\n",
      "tf.Tensor(\n",
      "[[1 1 1]\n",
      " [2 2 2]], shape=(2, 3), dtype=int32)\n",
      "<tf.Variable 'New Name:0' shape=(2, 3) dtype=int32, numpy=\n",
      "array([[1, 1, 1],\n",
      "       [2, 2, 2]])>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
       "array([[2, 2, 2],\n",
       "       [4, 4, 4]])>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#변수\n",
    "tensor1 = tf.constant([[0,1,2],[3,4,5]]) #메트릭스 선언\n",
    "print(tensor1)\n",
    "\n",
    "tensor_var1 = tf.Variable(tensor1) #변수 할당\n",
    "print(tensor_var1)\n",
    "\n",
    "print(\"이름 :\",tensor_var1.name)\n",
    "print(\"크기 :\",tensor_var1.shape)\n",
    "print(\"자료형 :\",tensor_var1.dtype)\n",
    "print(\"배열 :\",tensor_var1.numpy())\n",
    "\n",
    "tensor_var1.assign([[1,1,1],[2,2,2]]) #변수 재할당\n",
    "print(tensor_var1)\n",
    "\n",
    "tensor2 = tf.convert_to_tensor(tensor_var1) #변수를 텐서로 변환\n",
    "print(tensor2)\n",
    "\n",
    "tensor_var2 = tf.Variable(tensor2, name='New Name') #변수에 이름 할당\n",
    "print(tensor_var2)\n",
    "\n",
    "tensor_var1 + tensor_var2 #변수끼리 합산(단 출력물은 각 변수가 가지고 있는 텐서의 합으로 나타내므로 변수형태가 아닌 텐서로 나옴)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : [-0.20943771  1.2746525   1.213214   -0.17576952  1.876984    0.16379918\n",
      "  1.082245    0.6199966  -0.44402212  1.3048344 ]\n",
      "y : [-2.628313    1.8239574   1.6396422  -2.5273085   3.630952   -1.5086024\n",
      "  1.2467351  -0.14001012 -3.3320663   1.9145031 ]\n",
      "tf.Tensor(5.11122, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(4.555297, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(4.102832, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(3.7264862, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(3.4070325, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(3.1308815, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(2.8883655, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(2.6725478, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(2.478399, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(2.3022268, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(2.141275, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(1.9934533, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(1.8571408, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(1.7310549, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(1.6141573, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(1.5055892, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(1.4046257, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(1.3106416, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(1.2230909, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(1.1414891, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "EPOCH 20 - MSE : 1.1415 ----- a : 1.74 ------ b : -0.75\n",
      "tf.Tensor(1.0654008, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.9944326, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.92822516, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.8664486, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.80879956, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.7549972, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.7047815, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.657911, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.6141612, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.5733233, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.5352025, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.49961767, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.4663996, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.43539086, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.40644398, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.37942204, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.35419667, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.33064863, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.30866617, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.2881453, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "EPOCH 40 - MSE : 0.2881 ----- a : 2.37 ------ b : -1.37\n",
      "tf.Tensor(0.2689887, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.25110573, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.23441163, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.21882746, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.20427933, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.19069839, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.17802033, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.16618523, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.1551369, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.14482316, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.13519497, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.12620696, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.11781653, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.109983824, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.10267188, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.09584606, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.08947399, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.08352556, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.07797261, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.07278882, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "EPOCH 60 - MSE : 0.0728 ----- a : 2.69 ------ b : -1.68\n",
      "tf.Tensor(0.06794969, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.06343224, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.059215087, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.05527835, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.05160334, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.04817266, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.044970036, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.041980326, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.039189406, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.036584042, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.034151852, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.031881385, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.029761856, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.027783234, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.025936116, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.02421185, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.022602187, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.021099566, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.019696819, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.018387346, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "EPOCH 80 - MSE : 0.0184 ----- a : 2.84 ------ b : -1.84\n",
      "tf.Tensor(0.017164912, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.016023729, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.014958446, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.01396397, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.013035622, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.01216898, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.011359973, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.010604739, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.009899725, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.009241565, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.008627167, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.008053609, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.007518175, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.007018354, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0065517602, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.006116192, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0057095685, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0053299926, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.00497564, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.004644838, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "EPOCH 100 - MSE : 0.0046 ----- a : 2.92 ------ b : -1.92\n",
      "tf.Tensor(0.00433604, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.004047779, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.003778664, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0035274539, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0032929382, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0030740215, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0028696493, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0026788684, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.002500775, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0023345207, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0021793123, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0020344225, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0018991723, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0017729147, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0016550429, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0015450094, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0014422962, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0013464069, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0012568992, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0011733371, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "EPOCH 120 - MSE : 0.0012 ----- a : 2.96 ------ b : -1.96\n",
      "tf.Tensor(0.0010953353, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0010225122, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0009545331, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.00089107873, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0008318328, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.00077653246, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.00072490925, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0006767106, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0006317247, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0005897229, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0005505197, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.00051391876, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.00047975016, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0004478585, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.00041807978, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0003902872, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.00036434009, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0003401173, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.00031750533, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0002963942, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "EPOCH 140 - MSE : 0.0003 ----- a : 2.98 ------ b : -1.98\n",
      "tf.Tensor(0.00027669285, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.00025829676, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.00024112473, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0002250954, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.00021013214, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.00019616149, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.00018312043, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.00017094743, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.00015958307, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.00014897305, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.0001390697, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.00012982478, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.00012119398, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.000113136965, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(0.00010561539, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(9.859293e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(9.2038375e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(8.591929e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(8.020784e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(7.4875294e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "EPOCH 160 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "tf.Tensor(6.989822e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(6.525243e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(6.0913582e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(5.6864792e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(5.3084244e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(4.9555576e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(4.626149e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(4.3186308e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(4.0315197e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(3.7634694e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(3.5133195e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(3.2796757e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(3.0617073e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(2.8582444e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(2.668137e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(2.4907591e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(2.325196e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(2.1706617e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(2.0262743e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(1.8916187e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "EPOCH 180 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "tf.Tensor(1.7658163e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(1.6484195e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(1.5388365e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(1.4365529e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(1.34104175e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(1.2519413e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(1.1686949e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(1.0910039e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(1.0184293e-05, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(9.507528e-06, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(8.875337e-06, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(8.285768e-06, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(7.735149e-06, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(7.2203584e-06, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(6.740742e-06, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(6.2924387e-06, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(5.8736377e-06, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(5.483871e-06, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(5.1192337e-06, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "tf.Tensor(4.778576e-06, shape=(), dtype=float32)\n",
      "1\n",
      "2\n",
      "EPOCH 200 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n"
     ]
    }
   ],
   "source": [
    "#자동미분\n",
    "g = tf.random.Generator.from_seed(2020)\n",
    "x = g.normal(shape = (10,))\n",
    "y = 3*x-2\n",
    "\n",
    "print('x :',x.numpy())\n",
    "print('y :',y.numpy())\n",
    "\n",
    "#손실 함수 정의\n",
    "def cal_mse(x,y,a,b):\n",
    "    y_pred = a*x+b\n",
    "    squared_error = (y_pred - y)**2\n",
    "    mean_squared_error = tf.reduce_mean(squared_error)\n",
    "    return mean_squared_error\n",
    "\n",
    "\n",
    "a = tf.Variable(0.0)\n",
    "b = tf.Variable(0.0)\n",
    "\n",
    "EPOCHS = 200\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    with tf.GradientTape() as tape:\n",
    "        mse = cal_mse(x,y,a,b)\n",
    "    grad = tape.gradient(mse,{'a':a,'b':b})\n",
    "    d_a,d_b = grad['a'],grad['b']\n",
    "    \n",
    "    a.assign_sub(d_a*0.05)\n",
    "    b.assign_sub(d_b*0.05)\n",
    "    \n",
    "    if epoch%20 == 0:\n",
    "        print('EPOCH %d - MSE : %.4f ----- a : %.2f ------ b : %.2f'%(epoch, mse, a, b))\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x : [-0.20943771  1.2746525   1.213214   -0.17576952  1.876984    0.16379918\n",
      "  1.082245    0.6199966  -0.44402212  1.3048344 ]\n",
      "y : [-2.628313    1.8239574   1.6396422  -2.5273085   3.630952   -1.5086024\n",
      "  1.2467351  -0.14001012 -3.3320663   1.9145031 ]\n",
      "1    EPOCH 1 - MSE : 5.1112 ----- a : 0.00 ------ b : 0.00\n",
      "2    EPOCH 1 - MSE : 5.1112 ----- a : 0.17 ------ b : 0.00\n",
      "1    EPOCH 2 - MSE : 4.5553 ----- a : 0.17 ------ b : 0.00\n",
      "2    EPOCH 2 - MSE : 4.5553 ----- a : 0.32 ------ b : -0.01\n",
      "1    EPOCH 3 - MSE : 4.1028 ----- a : 0.32 ------ b : -0.01\n",
      "2    EPOCH 3 - MSE : 4.1028 ----- a : 0.46 ------ b : -0.03\n",
      "1    EPOCH 4 - MSE : 3.7265 ----- a : 0.46 ------ b : -0.03\n",
      "2    EPOCH 4 - MSE : 3.7265 ----- a : 0.59 ------ b : -0.06\n",
      "1    EPOCH 5 - MSE : 3.4070 ----- a : 0.59 ------ b : -0.06\n",
      "2    EPOCH 5 - MSE : 3.4070 ----- a : 0.70 ------ b : -0.09\n",
      "1    EPOCH 6 - MSE : 3.1309 ----- a : 0.70 ------ b : -0.09\n",
      "2    EPOCH 6 - MSE : 3.1309 ----- a : 0.81 ------ b : -0.13\n",
      "1    EPOCH 7 - MSE : 2.8884 ----- a : 0.81 ------ b : -0.13\n",
      "2    EPOCH 7 - MSE : 2.8884 ----- a : 0.91 ------ b : -0.17\n",
      "1    EPOCH 8 - MSE : 2.6725 ----- a : 0.91 ------ b : -0.17\n",
      "2    EPOCH 8 - MSE : 2.6725 ----- a : 1.00 ------ b : -0.21\n",
      "1    EPOCH 9 - MSE : 2.4784 ----- a : 1.00 ------ b : -0.21\n",
      "2    EPOCH 9 - MSE : 2.4784 ----- a : 1.08 ------ b : -0.25\n",
      "1    EPOCH 10 - MSE : 2.3022 ----- a : 1.08 ------ b : -0.25\n",
      "2    EPOCH 10 - MSE : 2.3022 ----- a : 1.16 ------ b : -0.30\n",
      "1    EPOCH 11 - MSE : 2.1413 ----- a : 1.16 ------ b : -0.30\n",
      "2    EPOCH 11 - MSE : 2.1413 ----- a : 1.23 ------ b : -0.35\n",
      "1    EPOCH 12 - MSE : 1.9935 ----- a : 1.23 ------ b : -0.35\n",
      "2    EPOCH 12 - MSE : 1.9935 ----- a : 1.30 ------ b : -0.39\n",
      "1    EPOCH 13 - MSE : 1.8571 ----- a : 1.30 ------ b : -0.39\n",
      "2    EPOCH 13 - MSE : 1.8571 ----- a : 1.37 ------ b : -0.44\n",
      "1    EPOCH 14 - MSE : 1.7311 ----- a : 1.37 ------ b : -0.44\n",
      "2    EPOCH 14 - MSE : 1.7311 ----- a : 1.43 ------ b : -0.49\n",
      "1    EPOCH 15 - MSE : 1.6142 ----- a : 1.43 ------ b : -0.49\n",
      "2    EPOCH 15 - MSE : 1.6142 ----- a : 1.49 ------ b : -0.53\n",
      "1    EPOCH 16 - MSE : 1.5056 ----- a : 1.49 ------ b : -0.53\n",
      "2    EPOCH 16 - MSE : 1.5056 ----- a : 1.54 ------ b : -0.58\n",
      "1    EPOCH 17 - MSE : 1.4046 ----- a : 1.54 ------ b : -0.58\n",
      "2    EPOCH 17 - MSE : 1.4046 ----- a : 1.60 ------ b : -0.62\n",
      "1    EPOCH 18 - MSE : 1.3106 ----- a : 1.60 ------ b : -0.62\n",
      "2    EPOCH 18 - MSE : 1.3106 ----- a : 1.65 ------ b : -0.67\n",
      "1    EPOCH 19 - MSE : 1.2231 ----- a : 1.65 ------ b : -0.67\n",
      "2    EPOCH 19 - MSE : 1.2231 ----- a : 1.69 ------ b : -0.71\n",
      "1    EPOCH 20 - MSE : 1.1415 ----- a : 1.69 ------ b : -0.71\n",
      "2    EPOCH 20 - MSE : 1.1415 ----- a : 1.74 ------ b : -0.75\n",
      "1    EPOCH 21 - MSE : 1.0654 ----- a : 1.74 ------ b : -0.75\n",
      "2    EPOCH 21 - MSE : 1.0654 ----- a : 1.78 ------ b : -0.79\n",
      "1    EPOCH 22 - MSE : 0.9944 ----- a : 1.78 ------ b : -0.79\n",
      "2    EPOCH 22 - MSE : 0.9944 ----- a : 1.83 ------ b : -0.83\n",
      "1    EPOCH 23 - MSE : 0.9282 ----- a : 1.83 ------ b : -0.83\n",
      "2    EPOCH 23 - MSE : 0.9282 ----- a : 1.87 ------ b : -0.87\n",
      "1    EPOCH 24 - MSE : 0.8664 ----- a : 1.87 ------ b : -0.87\n",
      "2    EPOCH 24 - MSE : 0.8664 ----- a : 1.91 ------ b : -0.91\n",
      "1    EPOCH 25 - MSE : 0.8088 ----- a : 1.91 ------ b : -0.91\n",
      "2    EPOCH 25 - MSE : 0.8088 ----- a : 1.95 ------ b : -0.94\n",
      "1    EPOCH 26 - MSE : 0.7550 ----- a : 1.95 ------ b : -0.94\n",
      "2    EPOCH 26 - MSE : 0.7550 ----- a : 1.98 ------ b : -0.98\n",
      "1    EPOCH 27 - MSE : 0.7048 ----- a : 1.98 ------ b : -0.98\n",
      "2    EPOCH 27 - MSE : 0.7048 ----- a : 2.02 ------ b : -1.01\n",
      "1    EPOCH 28 - MSE : 0.6579 ----- a : 2.02 ------ b : -1.01\n",
      "2    EPOCH 28 - MSE : 0.6579 ----- a : 2.05 ------ b : -1.04\n",
      "1    EPOCH 29 - MSE : 0.6142 ----- a : 2.05 ------ b : -1.04\n",
      "2    EPOCH 29 - MSE : 0.6142 ----- a : 2.08 ------ b : -1.08\n",
      "1    EPOCH 30 - MSE : 0.5733 ----- a : 2.08 ------ b : -1.08\n",
      "2    EPOCH 30 - MSE : 0.5733 ----- a : 2.11 ------ b : -1.11\n",
      "1    EPOCH 31 - MSE : 0.5352 ----- a : 2.11 ------ b : -1.11\n",
      "2    EPOCH 31 - MSE : 0.5352 ----- a : 2.14 ------ b : -1.14\n",
      "1    EPOCH 32 - MSE : 0.4996 ----- a : 2.14 ------ b : -1.14\n",
      "2    EPOCH 32 - MSE : 0.4996 ----- a : 2.17 ------ b : -1.17\n",
      "1    EPOCH 33 - MSE : 0.4664 ----- a : 2.17 ------ b : -1.17\n",
      "2    EPOCH 33 - MSE : 0.4664 ----- a : 2.20 ------ b : -1.19\n",
      "1    EPOCH 34 - MSE : 0.4354 ----- a : 2.20 ------ b : -1.19\n",
      "2    EPOCH 34 - MSE : 0.4354 ----- a : 2.23 ------ b : -1.22\n",
      "1    EPOCH 35 - MSE : 0.4064 ----- a : 2.23 ------ b : -1.22\n",
      "2    EPOCH 35 - MSE : 0.4064 ----- a : 2.26 ------ b : -1.25\n",
      "1    EPOCH 36 - MSE : 0.3794 ----- a : 2.26 ------ b : -1.25\n",
      "2    EPOCH 36 - MSE : 0.3794 ----- a : 2.28 ------ b : -1.27\n",
      "1    EPOCH 37 - MSE : 0.3542 ----- a : 2.28 ------ b : -1.27\n",
      "2    EPOCH 37 - MSE : 0.3542 ----- a : 2.30 ------ b : -1.30\n",
      "1    EPOCH 38 - MSE : 0.3306 ----- a : 2.30 ------ b : -1.30\n",
      "2    EPOCH 38 - MSE : 0.3306 ----- a : 2.33 ------ b : -1.32\n",
      "1    EPOCH 39 - MSE : 0.3087 ----- a : 2.33 ------ b : -1.32\n",
      "2    EPOCH 39 - MSE : 0.3087 ----- a : 2.35 ------ b : -1.34\n",
      "1    EPOCH 40 - MSE : 0.2881 ----- a : 2.35 ------ b : -1.34\n",
      "2    EPOCH 40 - MSE : 0.2881 ----- a : 2.37 ------ b : -1.37\n",
      "1    EPOCH 41 - MSE : 0.2690 ----- a : 2.37 ------ b : -1.37\n",
      "2    EPOCH 41 - MSE : 0.2690 ----- a : 2.39 ------ b : -1.39\n",
      "1    EPOCH 42 - MSE : 0.2511 ----- a : 2.39 ------ b : -1.39\n",
      "2    EPOCH 42 - MSE : 0.2511 ----- a : 2.41 ------ b : -1.41\n",
      "1    EPOCH 43 - MSE : 0.2344 ----- a : 2.41 ------ b : -1.41\n",
      "2    EPOCH 43 - MSE : 0.2344 ----- a : 2.43 ------ b : -1.43\n",
      "1    EPOCH 44 - MSE : 0.2188 ----- a : 2.43 ------ b : -1.43\n",
      "2    EPOCH 44 - MSE : 0.2188 ----- a : 2.45 ------ b : -1.45\n",
      "1    EPOCH 45 - MSE : 0.2043 ----- a : 2.45 ------ b : -1.45\n",
      "2    EPOCH 45 - MSE : 0.2043 ----- a : 2.47 ------ b : -1.47\n",
      "1    EPOCH 46 - MSE : 0.1907 ----- a : 2.47 ------ b : -1.47\n",
      "2    EPOCH 46 - MSE : 0.1907 ----- a : 2.49 ------ b : -1.48\n",
      "1    EPOCH 47 - MSE : 0.1780 ----- a : 2.49 ------ b : -1.48\n",
      "2    EPOCH 47 - MSE : 0.1780 ----- a : 2.51 ------ b : -1.50\n",
      "1    EPOCH 48 - MSE : 0.1662 ----- a : 2.51 ------ b : -1.50\n",
      "2    EPOCH 48 - MSE : 0.1662 ----- a : 2.52 ------ b : -1.52\n",
      "1    EPOCH 49 - MSE : 0.1551 ----- a : 2.52 ------ b : -1.52\n",
      "2    EPOCH 49 - MSE : 0.1551 ----- a : 2.54 ------ b : -1.53\n",
      "1    EPOCH 50 - MSE : 0.1448 ----- a : 2.54 ------ b : -1.53\n",
      "2    EPOCH 50 - MSE : 0.1448 ----- a : 2.56 ------ b : -1.55\n",
      "1    EPOCH 51 - MSE : 0.1352 ----- a : 2.56 ------ b : -1.55\n",
      "2    EPOCH 51 - MSE : 0.1352 ----- a : 2.57 ------ b : -1.57\n",
      "1    EPOCH 52 - MSE : 0.1262 ----- a : 2.57 ------ b : -1.57\n",
      "2    EPOCH 52 - MSE : 0.1262 ----- a : 2.59 ------ b : -1.58\n",
      "1    EPOCH 53 - MSE : 0.1178 ----- a : 2.59 ------ b : -1.58\n",
      "2    EPOCH 53 - MSE : 0.1178 ----- a : 2.60 ------ b : -1.59\n",
      "1    EPOCH 54 - MSE : 0.1100 ----- a : 2.60 ------ b : -1.59\n",
      "2    EPOCH 54 - MSE : 0.1100 ----- a : 2.61 ------ b : -1.61\n",
      "1    EPOCH 55 - MSE : 0.1027 ----- a : 2.61 ------ b : -1.61\n",
      "2    EPOCH 55 - MSE : 0.1027 ----- a : 2.63 ------ b : -1.62\n",
      "1    EPOCH 56 - MSE : 0.0958 ----- a : 2.63 ------ b : -1.62\n",
      "2    EPOCH 56 - MSE : 0.0958 ----- a : 2.64 ------ b : -1.63\n",
      "1    EPOCH 57 - MSE : 0.0895 ----- a : 2.64 ------ b : -1.63\n",
      "2    EPOCH 57 - MSE : 0.0895 ----- a : 2.65 ------ b : -1.65\n",
      "1    EPOCH 58 - MSE : 0.0835 ----- a : 2.65 ------ b : -1.65\n",
      "2    EPOCH 58 - MSE : 0.0835 ----- a : 2.66 ------ b : -1.66\n",
      "1    EPOCH 59 - MSE : 0.0780 ----- a : 2.66 ------ b : -1.66\n",
      "2    EPOCH 59 - MSE : 0.0780 ----- a : 2.67 ------ b : -1.67\n",
      "1    EPOCH 60 - MSE : 0.0728 ----- a : 2.67 ------ b : -1.67\n",
      "2    EPOCH 60 - MSE : 0.0728 ----- a : 2.69 ------ b : -1.68\n",
      "1    EPOCH 61 - MSE : 0.0679 ----- a : 2.69 ------ b : -1.68\n",
      "2    EPOCH 61 - MSE : 0.0679 ----- a : 2.70 ------ b : -1.69\n",
      "1    EPOCH 62 - MSE : 0.0634 ----- a : 2.70 ------ b : -1.69\n",
      "2    EPOCH 62 - MSE : 0.0634 ----- a : 2.71 ------ b : -1.70\n",
      "1    EPOCH 63 - MSE : 0.0592 ----- a : 2.71 ------ b : -1.70\n",
      "2    EPOCH 63 - MSE : 0.0592 ----- a : 2.72 ------ b : -1.71\n",
      "1    EPOCH 64 - MSE : 0.0553 ----- a : 2.72 ------ b : -1.71\n",
      "2    EPOCH 64 - MSE : 0.0553 ----- a : 2.73 ------ b : -1.72\n",
      "1    EPOCH 65 - MSE : 0.0516 ----- a : 2.73 ------ b : -1.72\n",
      "2    EPOCH 65 - MSE : 0.0516 ----- a : 2.73 ------ b : -1.73\n",
      "1    EPOCH 66 - MSE : 0.0482 ----- a : 2.73 ------ b : -1.73\n",
      "2    EPOCH 66 - MSE : 0.0482 ----- a : 2.74 ------ b : -1.74\n",
      "1    EPOCH 67 - MSE : 0.0450 ----- a : 2.74 ------ b : -1.74\n",
      "2    EPOCH 67 - MSE : 0.0450 ----- a : 2.75 ------ b : -1.75\n",
      "1    EPOCH 68 - MSE : 0.0420 ----- a : 2.75 ------ b : -1.75\n",
      "2    EPOCH 68 - MSE : 0.0420 ----- a : 2.76 ------ b : -1.76\n",
      "1    EPOCH 69 - MSE : 0.0392 ----- a : 2.76 ------ b : -1.76\n",
      "2    EPOCH 69 - MSE : 0.0392 ----- a : 2.77 ------ b : -1.77\n",
      "1    EPOCH 70 - MSE : 0.0366 ----- a : 2.77 ------ b : -1.77\n",
      "2    EPOCH 70 - MSE : 0.0366 ----- a : 2.78 ------ b : -1.77\n",
      "1    EPOCH 71 - MSE : 0.0342 ----- a : 2.78 ------ b : -1.77\n",
      "2    EPOCH 71 - MSE : 0.0342 ----- a : 2.78 ------ b : -1.78\n",
      "1    EPOCH 72 - MSE : 0.0319 ----- a : 2.78 ------ b : -1.78\n",
      "2    EPOCH 72 - MSE : 0.0319 ----- a : 2.79 ------ b : -1.79\n",
      "1    EPOCH 73 - MSE : 0.0298 ----- a : 2.79 ------ b : -1.79\n",
      "2    EPOCH 73 - MSE : 0.0298 ----- a : 2.80 ------ b : -1.80\n",
      "1    EPOCH 74 - MSE : 0.0278 ----- a : 2.80 ------ b : -1.80\n",
      "2    EPOCH 74 - MSE : 0.0278 ----- a : 2.81 ------ b : -1.80\n",
      "1    EPOCH 75 - MSE : 0.0259 ----- a : 2.81 ------ b : -1.80\n",
      "2    EPOCH 75 - MSE : 0.0259 ----- a : 2.81 ------ b : -1.81\n",
      "1    EPOCH 76 - MSE : 0.0242 ----- a : 2.81 ------ b : -1.81\n",
      "2    EPOCH 76 - MSE : 0.0242 ----- a : 2.82 ------ b : -1.82\n",
      "1    EPOCH 77 - MSE : 0.0226 ----- a : 2.82 ------ b : -1.82\n",
      "2    EPOCH 77 - MSE : 0.0226 ----- a : 2.82 ------ b : -1.82\n",
      "1    EPOCH 78 - MSE : 0.0211 ----- a : 2.82 ------ b : -1.82\n",
      "2    EPOCH 78 - MSE : 0.0211 ----- a : 2.83 ------ b : -1.83\n",
      "1    EPOCH 79 - MSE : 0.0197 ----- a : 2.83 ------ b : -1.83\n",
      "2    EPOCH 79 - MSE : 0.0197 ----- a : 2.84 ------ b : -1.83\n",
      "1    EPOCH 80 - MSE : 0.0184 ----- a : 2.84 ------ b : -1.83\n",
      "2    EPOCH 80 - MSE : 0.0184 ----- a : 2.84 ------ b : -1.84\n",
      "1    EPOCH 81 - MSE : 0.0172 ----- a : 2.84 ------ b : -1.84\n",
      "2    EPOCH 81 - MSE : 0.0172 ----- a : 2.85 ------ b : -1.85\n",
      "1    EPOCH 82 - MSE : 0.0160 ----- a : 2.85 ------ b : -1.85\n",
      "2    EPOCH 82 - MSE : 0.0160 ----- a : 2.85 ------ b : -1.85\n",
      "1    EPOCH 83 - MSE : 0.0150 ----- a : 2.85 ------ b : -1.85\n",
      "2    EPOCH 83 - MSE : 0.0150 ----- a : 2.86 ------ b : -1.86\n",
      "1    EPOCH 84 - MSE : 0.0140 ----- a : 2.86 ------ b : -1.86\n",
      "2    EPOCH 84 - MSE : 0.0140 ----- a : 2.86 ------ b : -1.86\n",
      "1    EPOCH 85 - MSE : 0.0130 ----- a : 2.86 ------ b : -1.86\n",
      "2    EPOCH 85 - MSE : 0.0130 ----- a : 2.87 ------ b : -1.86\n",
      "1    EPOCH 86 - MSE : 0.0122 ----- a : 2.87 ------ b : -1.86\n",
      "2    EPOCH 86 - MSE : 0.0122 ----- a : 2.87 ------ b : -1.87\n",
      "1    EPOCH 87 - MSE : 0.0114 ----- a : 2.87 ------ b : -1.87\n",
      "2    EPOCH 87 - MSE : 0.0114 ----- a : 2.88 ------ b : -1.87\n",
      "1    EPOCH 88 - MSE : 0.0106 ----- a : 2.88 ------ b : -1.87\n",
      "2    EPOCH 88 - MSE : 0.0106 ----- a : 2.88 ------ b : -1.88\n",
      "1    EPOCH 89 - MSE : 0.0099 ----- a : 2.88 ------ b : -1.88\n",
      "2    EPOCH 89 - MSE : 0.0099 ----- a : 2.88 ------ b : -1.88\n",
      "1    EPOCH 90 - MSE : 0.0092 ----- a : 2.88 ------ b : -1.88\n",
      "2    EPOCH 90 - MSE : 0.0092 ----- a : 2.89 ------ b : -1.89\n",
      "1    EPOCH 91 - MSE : 0.0086 ----- a : 2.89 ------ b : -1.89\n",
      "2    EPOCH 91 - MSE : 0.0086 ----- a : 2.89 ------ b : -1.89\n",
      "1    EPOCH 92 - MSE : 0.0081 ----- a : 2.89 ------ b : -1.89\n",
      "2    EPOCH 92 - MSE : 0.0081 ----- a : 2.90 ------ b : -1.89\n",
      "1    EPOCH 93 - MSE : 0.0075 ----- a : 2.90 ------ b : -1.89\n",
      "2    EPOCH 93 - MSE : 0.0075 ----- a : 2.90 ------ b : -1.90\n",
      "1    EPOCH 94 - MSE : 0.0070 ----- a : 2.90 ------ b : -1.90\n",
      "2    EPOCH 94 - MSE : 0.0070 ----- a : 2.90 ------ b : -1.90\n",
      "1    EPOCH 95 - MSE : 0.0066 ----- a : 2.90 ------ b : -1.90\n",
      "2    EPOCH 95 - MSE : 0.0066 ----- a : 2.91 ------ b : -1.90\n",
      "1    EPOCH 96 - MSE : 0.0061 ----- a : 2.91 ------ b : -1.90\n",
      "2    EPOCH 96 - MSE : 0.0061 ----- a : 2.91 ------ b : -1.91\n",
      "1    EPOCH 97 - MSE : 0.0057 ----- a : 2.91 ------ b : -1.91\n",
      "2    EPOCH 97 - MSE : 0.0057 ----- a : 2.91 ------ b : -1.91\n",
      "1    EPOCH 98 - MSE : 0.0053 ----- a : 2.91 ------ b : -1.91\n",
      "2    EPOCH 98 - MSE : 0.0053 ----- a : 2.91 ------ b : -1.91\n",
      "1    EPOCH 99 - MSE : 0.0050 ----- a : 2.91 ------ b : -1.91\n",
      "2    EPOCH 99 - MSE : 0.0050 ----- a : 2.92 ------ b : -1.92\n",
      "1    EPOCH 100 - MSE : 0.0046 ----- a : 2.92 ------ b : -1.92\n",
      "2    EPOCH 100 - MSE : 0.0046 ----- a : 2.92 ------ b : -1.92\n",
      "1    EPOCH 101 - MSE : 0.0043 ----- a : 2.92 ------ b : -1.92\n",
      "2    EPOCH 101 - MSE : 0.0043 ----- a : 2.92 ------ b : -1.92\n",
      "1    EPOCH 102 - MSE : 0.0040 ----- a : 2.92 ------ b : -1.92\n",
      "2    EPOCH 102 - MSE : 0.0040 ----- a : 2.93 ------ b : -1.92\n",
      "1    EPOCH 103 - MSE : 0.0038 ----- a : 2.93 ------ b : -1.92\n",
      "2    EPOCH 103 - MSE : 0.0038 ----- a : 2.93 ------ b : -1.93\n",
      "1    EPOCH 104 - MSE : 0.0035 ----- a : 2.93 ------ b : -1.93\n",
      "2    EPOCH 104 - MSE : 0.0035 ----- a : 2.93 ------ b : -1.93\n",
      "1    EPOCH 105 - MSE : 0.0033 ----- a : 2.93 ------ b : -1.93\n",
      "2    EPOCH 105 - MSE : 0.0033 ----- a : 2.93 ------ b : -1.93\n",
      "1    EPOCH 106 - MSE : 0.0031 ----- a : 2.93 ------ b : -1.93\n",
      "2    EPOCH 106 - MSE : 0.0031 ----- a : 2.94 ------ b : -1.93\n",
      "1    EPOCH 107 - MSE : 0.0029 ----- a : 2.94 ------ b : -1.93\n",
      "2    EPOCH 107 - MSE : 0.0029 ----- a : 2.94 ------ b : -1.94\n",
      "1    EPOCH 108 - MSE : 0.0027 ----- a : 2.94 ------ b : -1.94\n",
      "2    EPOCH 108 - MSE : 0.0027 ----- a : 2.94 ------ b : -1.94\n",
      "1    EPOCH 109 - MSE : 0.0025 ----- a : 2.94 ------ b : -1.94\n",
      "2    EPOCH 109 - MSE : 0.0025 ----- a : 2.94 ------ b : -1.94\n",
      "1    EPOCH 110 - MSE : 0.0023 ----- a : 2.94 ------ b : -1.94\n",
      "2    EPOCH 110 - MSE : 0.0023 ----- a : 2.94 ------ b : -1.94\n",
      "1    EPOCH 111 - MSE : 0.0022 ----- a : 2.94 ------ b : -1.94\n",
      "2    EPOCH 111 - MSE : 0.0022 ----- a : 2.95 ------ b : -1.94\n",
      "1    EPOCH 112 - MSE : 0.0020 ----- a : 2.95 ------ b : -1.94\n",
      "2    EPOCH 112 - MSE : 0.0020 ----- a : 2.95 ------ b : -1.95\n",
      "1    EPOCH 113 - MSE : 0.0019 ----- a : 2.95 ------ b : -1.95\n",
      "2    EPOCH 113 - MSE : 0.0019 ----- a : 2.95 ------ b : -1.95\n",
      "1    EPOCH 114 - MSE : 0.0018 ----- a : 2.95 ------ b : -1.95\n",
      "2    EPOCH 114 - MSE : 0.0018 ----- a : 2.95 ------ b : -1.95\n",
      "1    EPOCH 115 - MSE : 0.0017 ----- a : 2.95 ------ b : -1.95\n",
      "2    EPOCH 115 - MSE : 0.0017 ----- a : 2.95 ------ b : -1.95\n",
      "1    EPOCH 116 - MSE : 0.0015 ----- a : 2.95 ------ b : -1.95\n",
      "2    EPOCH 116 - MSE : 0.0015 ----- a : 2.95 ------ b : -1.95\n",
      "1    EPOCH 117 - MSE : 0.0014 ----- a : 2.95 ------ b : -1.95\n",
      "2    EPOCH 117 - MSE : 0.0014 ----- a : 2.96 ------ b : -1.96\n",
      "1    EPOCH 118 - MSE : 0.0013 ----- a : 2.96 ------ b : -1.96\n",
      "2    EPOCH 118 - MSE : 0.0013 ----- a : 2.96 ------ b : -1.96\n",
      "1    EPOCH 119 - MSE : 0.0013 ----- a : 2.96 ------ b : -1.96\n",
      "2    EPOCH 119 - MSE : 0.0013 ----- a : 2.96 ------ b : -1.96\n",
      "1    EPOCH 120 - MSE : 0.0012 ----- a : 2.96 ------ b : -1.96\n",
      "2    EPOCH 120 - MSE : 0.0012 ----- a : 2.96 ------ b : -1.96\n",
      "1    EPOCH 121 - MSE : 0.0011 ----- a : 2.96 ------ b : -1.96\n",
      "2    EPOCH 121 - MSE : 0.0011 ----- a : 2.96 ------ b : -1.96\n",
      "1    EPOCH 122 - MSE : 0.0010 ----- a : 2.96 ------ b : -1.96\n",
      "2    EPOCH 122 - MSE : 0.0010 ----- a : 2.96 ------ b : -1.96\n",
      "1    EPOCH 123 - MSE : 0.0010 ----- a : 2.96 ------ b : -1.96\n",
      "2    EPOCH 123 - MSE : 0.0010 ----- a : 2.96 ------ b : -1.96\n",
      "1    EPOCH 124 - MSE : 0.0009 ----- a : 2.96 ------ b : -1.96\n",
      "2    EPOCH 124 - MSE : 0.0009 ----- a : 2.97 ------ b : -1.96\n",
      "1    EPOCH 125 - MSE : 0.0008 ----- a : 2.97 ------ b : -1.96\n",
      "2    EPOCH 125 - MSE : 0.0008 ----- a : 2.97 ------ b : -1.97\n",
      "1    EPOCH 126 - MSE : 0.0008 ----- a : 2.97 ------ b : -1.97\n",
      "2    EPOCH 126 - MSE : 0.0008 ----- a : 2.97 ------ b : -1.97\n",
      "1    EPOCH 127 - MSE : 0.0007 ----- a : 2.97 ------ b : -1.97\n",
      "2    EPOCH 127 - MSE : 0.0007 ----- a : 2.97 ------ b : -1.97\n",
      "1    EPOCH 128 - MSE : 0.0007 ----- a : 2.97 ------ b : -1.97\n",
      "2    EPOCH 128 - MSE : 0.0007 ----- a : 2.97 ------ b : -1.97\n",
      "1    EPOCH 129 - MSE : 0.0006 ----- a : 2.97 ------ b : -1.97\n",
      "2    EPOCH 129 - MSE : 0.0006 ----- a : 2.97 ------ b : -1.97\n",
      "1    EPOCH 130 - MSE : 0.0006 ----- a : 2.97 ------ b : -1.97\n",
      "2    EPOCH 130 - MSE : 0.0006 ----- a : 2.97 ------ b : -1.97\n",
      "1    EPOCH 131 - MSE : 0.0006 ----- a : 2.97 ------ b : -1.97\n",
      "2    EPOCH 131 - MSE : 0.0006 ----- a : 2.97 ------ b : -1.97\n",
      "1    EPOCH 132 - MSE : 0.0005 ----- a : 2.97 ------ b : -1.97\n",
      "2    EPOCH 132 - MSE : 0.0005 ----- a : 2.97 ------ b : -1.97\n",
      "1    EPOCH 133 - MSE : 0.0005 ----- a : 2.97 ------ b : -1.97\n",
      "2    EPOCH 133 - MSE : 0.0005 ----- a : 2.97 ------ b : -1.97\n",
      "1    EPOCH 134 - MSE : 0.0004 ----- a : 2.97 ------ b : -1.97\n",
      "2    EPOCH 134 - MSE : 0.0004 ----- a : 2.98 ------ b : -1.97\n",
      "1    EPOCH 135 - MSE : 0.0004 ----- a : 2.98 ------ b : -1.97\n",
      "2    EPOCH 135 - MSE : 0.0004 ----- a : 2.98 ------ b : -1.98\n",
      "1    EPOCH 136 - MSE : 0.0004 ----- a : 2.98 ------ b : -1.98\n",
      "2    EPOCH 136 - MSE : 0.0004 ----- a : 2.98 ------ b : -1.98\n",
      "1    EPOCH 137 - MSE : 0.0004 ----- a : 2.98 ------ b : -1.98\n",
      "2    EPOCH 137 - MSE : 0.0004 ----- a : 2.98 ------ b : -1.98\n",
      "1    EPOCH 138 - MSE : 0.0003 ----- a : 2.98 ------ b : -1.98\n",
      "2    EPOCH 138 - MSE : 0.0003 ----- a : 2.98 ------ b : -1.98\n",
      "1    EPOCH 139 - MSE : 0.0003 ----- a : 2.98 ------ b : -1.98\n",
      "2    EPOCH 139 - MSE : 0.0003 ----- a : 2.98 ------ b : -1.98\n",
      "1    EPOCH 140 - MSE : 0.0003 ----- a : 2.98 ------ b : -1.98\n",
      "2    EPOCH 140 - MSE : 0.0003 ----- a : 2.98 ------ b : -1.98\n",
      "1    EPOCH 141 - MSE : 0.0003 ----- a : 2.98 ------ b : -1.98\n",
      "2    EPOCH 141 - MSE : 0.0003 ----- a : 2.98 ------ b : -1.98\n",
      "1    EPOCH 142 - MSE : 0.0003 ----- a : 2.98 ------ b : -1.98\n",
      "2    EPOCH 142 - MSE : 0.0003 ----- a : 2.98 ------ b : -1.98\n",
      "1    EPOCH 143 - MSE : 0.0002 ----- a : 2.98 ------ b : -1.98\n",
      "2    EPOCH 143 - MSE : 0.0002 ----- a : 2.98 ------ b : -1.98\n",
      "1    EPOCH 144 - MSE : 0.0002 ----- a : 2.98 ------ b : -1.98\n",
      "2    EPOCH 144 - MSE : 0.0002 ----- a : 2.98 ------ b : -1.98\n",
      "1    EPOCH 145 - MSE : 0.0002 ----- a : 2.98 ------ b : -1.98\n",
      "2    EPOCH 145 - MSE : 0.0002 ----- a : 2.98 ------ b : -1.98\n",
      "1    EPOCH 146 - MSE : 0.0002 ----- a : 2.98 ------ b : -1.98\n",
      "2    EPOCH 146 - MSE : 0.0002 ----- a : 2.98 ------ b : -1.98\n",
      "1    EPOCH 147 - MSE : 0.0002 ----- a : 2.98 ------ b : -1.98\n",
      "2    EPOCH 147 - MSE : 0.0002 ----- a : 2.98 ------ b : -1.98\n",
      "1    EPOCH 148 - MSE : 0.0002 ----- a : 2.98 ------ b : -1.98\n",
      "2    EPOCH 148 - MSE : 0.0002 ----- a : 2.98 ------ b : -1.98\n",
      "1    EPOCH 149 - MSE : 0.0002 ----- a : 2.98 ------ b : -1.98\n",
      "2    EPOCH 149 - MSE : 0.0002 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 150 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 150 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 151 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 151 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 152 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 152 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 153 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 153 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 154 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 154 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 155 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 155 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 156 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 156 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 157 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 157 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 158 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 158 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 159 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 159 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 160 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 160 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 161 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 161 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 162 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 162 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 163 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 163 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 164 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 164 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 165 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 165 - MSE : 0.0001 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 166 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 166 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 167 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 167 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 168 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 168 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 169 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 169 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 170 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 170 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 171 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 171 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 172 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 172 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 173 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 173 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 174 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 174 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 175 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 175 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 176 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 176 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 177 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 177 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 178 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 178 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 179 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 179 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 180 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 180 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "1    EPOCH 181 - MSE : 0.0000 ----- a : 2.99 ------ b : -1.99\n",
      "2    EPOCH 181 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "1    EPOCH 182 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "2    EPOCH 182 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "1    EPOCH 183 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "2    EPOCH 183 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "1    EPOCH 184 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "2    EPOCH 184 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "1    EPOCH 185 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "2    EPOCH 185 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "1    EPOCH 186 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "2    EPOCH 186 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "1    EPOCH 187 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "2    EPOCH 187 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "1    EPOCH 188 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "2    EPOCH 188 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "1    EPOCH 189 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "2    EPOCH 189 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "1    EPOCH 190 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "2    EPOCH 190 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "1    EPOCH 191 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "2    EPOCH 191 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "1    EPOCH 192 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "2    EPOCH 192 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "1    EPOCH 193 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "2    EPOCH 193 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "1    EPOCH 194 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "2    EPOCH 194 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "1    EPOCH 195 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "2    EPOCH 195 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "1    EPOCH 196 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "2    EPOCH 196 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "1    EPOCH 197 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "2    EPOCH 197 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "1    EPOCH 198 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "2    EPOCH 198 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "1    EPOCH 199 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "2    EPOCH 199 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "1    EPOCH 200 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n",
      "2    EPOCH 200 - MSE : 0.0000 ----- a : 3.00 ------ b : -2.00\n"
     ]
    }
   ],
   "source": [
    "#자동미분\n",
    "g = tf.random.Generator.from_seed(2020)\n",
    "x = g.normal(shape = (10,))\n",
    "y = 3*x-2\n",
    "\n",
    "print('x :',x.numpy())\n",
    "print('y :',y.numpy())\n",
    "\n",
    "#손실 함수 정의\n",
    "def cal_mse(x,y,a,b):\n",
    "    y_pred = a*x+b\n",
    "    squared_error = (y_pred - y)**2\n",
    "    mean_squared_error = tf.reduce_mean(squared_error)\n",
    "    return mean_squared_error\n",
    "\n",
    "\n",
    "a = tf.Variable(0.0)\n",
    "b = tf.Variable(0.0)\n",
    "\n",
    "EPOCHS = 200\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    with tf.GradientTape() as tape:\n",
    "        mse = cal_mse(x,y,a,b)\n",
    "    grad = tape.gradient(mse,{'a':a,'b':b})\n",
    "    d_a,d_b = grad['a'],grad['b']\n",
    "    print('1    EPOCH %d - MSE : %.4f ----- a : %.2f ------ b : %.2f'%(epoch, mse, a, b))\n",
    "    \n",
    "    a.assign_sub(d_a*0.05)\n",
    "    b.assign_sub(d_b*0.05)\n",
    "\n",
    "    print('2    EPOCH %d - MSE : %.4f ----- a : %.2f ------ b : %.2f'%(epoch, mse, a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:0.3,b:0.5\n",
      " 0     w = 0.62957, b = 0.20001     error = 6.97863\n",
      " 5     w = 0.61657, b = 0.34234     error = 0.51225\n",
      "10     w = 0.56159, b = 0.37088     error = 0.34871\n",
      "15     w = 0.51586, b = 0.39366     error = 0.23774\n",
      "20     w = 0.47814, b = 0.41245     error = 0.16224\n",
      "25     w = 0.44702, b = 0.42795     error = 0.11086\n",
      "30     w = 0.42135, b = 0.44074     error = 0.07591\n",
      "35     w = 0.40018, b = 0.45128     error = 0.05212\n",
      "40     w = 0.38272, b = 0.45998     error = 0.03594\n",
      "45     w = 0.36831, b = 0.46716     error = 0.02493\n",
      "50     w = 0.35643, b = 0.47307     error = 0.01744\n",
      "55     w = 0.34663, b = 0.47796     error = 0.01234\n",
      "60     w = 0.33854, b = 0.48198     error = 0.00887\n",
      "65     w = 0.33187, b = 0.48531     error = 0.00651\n",
      "------------------------------------------------------------\n",
      "70     w = 0.3, b = 0.5     error = 0.00490\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlcAAAGpCAYAAACgSxNwAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAnB0lEQVR4nO3da3Al513n8d+/+1x0H41mNKOxx+MZJ5OZdRJfEmXIZXGRhICTQEItS+EUsFmg1gUVFqcWCIE3u8BCsS8WCLtZqrzGEMhtQ0jYbICQVOIsm8rNmtjxdRxfMrbluUjjuWh0O0fnnP++6JZ0pJEsadSPjqT+fqpOnT7dffp5zlPjmZ+f5+mnzd0FAACAbEStrgAAAMB2QrgCAADIEOEKAAAgQ4QrAACADBGuAAAAMlRodQWa7d692w8ePNjqagAAAKzo+PHj59y9f/H+TRWuDh48qKGhoVZXAwAAYEVm9uxS+xkWBAAAyBDhCgAAIEOEKwAAgAwRrgAAADJEuAIAAMgQ4QoAACBDhCsAAIAMEa4AAAAyRLgCAADIEOEKAAAgQ4QrAACADAULV2Z2xMwebHqNmdn7Q5UHAACwGQR7cLO7PyHpFkkys1jSC5I+G6o8AACAzWCjhgXfKulpd1/y6dEAAADbxUaFqzskfWKDylrWyXMTev78ZKurAQAAtrHg4crMSpLeJelvljl+p5kNmdnQ6Oho0Lr80keP63c//1jQMgAAQL5tRM/V2yV9x93PLnXQ3e9290F3H+zv7w9akXIhUrXWCFoGAADIt40IV+/RJhgSlKQS4QoAAAQWNFyZWYekt0n6TMhyVqtUiFStE64AAEA4wZZikCR3n5S0K2QZa1GKI41N1VpdDQAAsI3laoV2hgUBAEBoOQtXMcOCAAAgqHyFq5ieKwAAEFa+wlUhUqVWb3U1AADANparcFUuRKrQcwUAAALKVbhiQjsAAAgtV+GqnK5z5e6trgoAANimchWuSnEkd6nWIFwBAIAw8hWuCsnPZWgQAACEQrgCAADIUD7DFQuJAgCAQPIVrmJ6rgAAQFj5CldpzxVrXQEAgFByFa7KzLkCAACB5SpcMecKAACElq9wFceSpMoMzxcEAABh5Ctc0XMFAAACy2e4Ys4VAAAIJF/hiqUYAABAYLkKV+Uiw4IAACCsXIWr2Z4r1rkCAACh5Cpcsc4VAAAILVfhigntAAAgtHyGK+ZcAQCAQPIVrrhbEAAABJarcFWII0VGuAIAAOHkKlxJydAgw4IAACCU/IWrOKLnCgAABJO/cFWIVanx4GYAABBG7sJVuRCxiCgAAAgmd+GqVGBYEAAAhJO7cFUmXAEAgIByF664WxAAAISUv3DF3YIAACCg/IUrhgUBAEBA+QxXDAsCAIBA8heuGBYEAAAB5S9cMSwIAAACymW4YhFRAAAQSu7CVZk5VwAAIKDchatSHKkyw7MFAQBAGEHDlZn1mtmnzeyEmT1uZm8IWd5qcLcgAAAIqRD4+h+S9AV3/9dmVpLUEbi8FTGhHQAAhBQsXJlZj6TbJP1bSXL3qqRqqPJWqxTHarhUqzdUiHM3KgoAAAILmS5ukDQq6S/M7AEzu8fMOhefZGZ3mtmQmQ2Njo4GrE6iXEx+MkODAAAghJDhqiDpNZL+zN1vlTQh6YOLT3L3u9190N0H+/v7A1YnUUp7qxgaBAAAIYQMV8OSht39W+nnTysJWy1VKhCuAABAOMHClbufkfS8mR1Jd71V0mOhylut2XDFQqIAACCE0HcL/ntJH0vvFHxG0s8HLm9F5QJzrgAAQDhBw5W7PyhpMGQZa8WcKwAAEFLu1iJgzhUAAAgpv+GKYUEAABBA/sIVw4IAACCg/IWrubsFeXgzAADIXm7DFT1XAAAghNyFqzLrXAEAgIByGK5iSfRcAQCAMHIXrrhbEAAAhJS/cMXdggAAIKD8hSsmtAMAgIAIVwAAABnKXbgqRCYz5lwBAIAwcheuzEylOKLnCgAABJG7cCUlQ4OscwUAAELIZbgqFyKGBQEAQBC5DFelOFJlhnAFAACyl89wRc8VAAAIJL/hqlZvdTUAAMA2lONwRc8VAADIXi7DVbkQMywIAACCyGW4Yp0rAAAQSj7DFcOCAAAgkNyGKxYRBQAAIeQ2XDHnCgAAhJDLcFVmzhUAAAgkl+GKOVcAACCU/IYrhgUBAEAA+QxXPFsQAAAEks9wRc8VAAAIJLfhqt5w1Rve6qoAAIBtJrfhShKT2gEAQObyGa5iwhUAAAgjl+GqXIwlSZV6vcU1AQAA200+wxU9VwAAIJBchivmXAEAgFDyHa5YjgEAAGQsn+GKYUEAABBIPsMVw4IAACAQwhUAAECGch2uKsy5AgAAGctnuErnXPHwZgAAkLVCyIub2UlJlyXVJdXcfTBkeatV5m5BAAAQSNBwlXqzu5/bgHJWjTlXAAAglHwOCxKuAABAIKHDlUv6opkdN7M7lzrBzO40syEzGxodHQ1cnUS5kDxbsFrj2YIAACBbocPVm9z9NZLeLul9Znbb4hPc/W53H3T3wf7+/sDVSbBCOwAACCVouHL3U+n7iKTPSjoWsrzVYoV2AAAQSrBwZWadZtY9uy3pRyQ9Eqq8tSjGJolwBQAAshfybsG9kj5rZrPlfNzdvxCwvFUzM5UKEYuIAgCAzAULV+7+jKSbQ11/vcpxRM8VAADIXC6XYpCSSe2EKwAAkDXCFQAAQIZyHa4qhCsAAJCx/IYr5lwBAIAA8huuChGLiAIAgMzlO1zRcwUAADKW33DFsCAAAAggt+GqXIxZRBQAAGQut+GKnisAABBCbsNVuRCpWqu3uhoAAGCbyW244m5BAAAQQn7DFcOCAAAggPyGK5ZiAAAAARCuAAAAMpTrcMWzBQEAQNbyG67iSLWGq9HwVlcFAABsI/kNV4Xkp3PHIAAAyFJuw1U5DVcMDQIAgCzlNlzN9VwRrgAAQIZyG67KDAsCAIAAchuu6LkCAAAh5DdcxbEkwhUAAMhWfsMVPVcAACAAwlW93uKaAACA7SS/4SpmKQYAAJC9/IYrhgUBAEAAuQ1XZcIVAAAIILfhqsQK7QAAIID8hquYnisAAJC9/IYrVmgHAAABEK7ouQIAABkiXBGuAABAhnIbrnhwMwAACCG34YpFRAEAQAi5DVdmplIcMSwIAAAyldtwJSXzrghXAAAgS4QrHtwMAAAylO9wxbAgAADIWL7DFcOCAAAgY7kPV9wtCAAAshQ8XJlZbGYPmNnnQ5e1VgwLAgCArG1Ez9Vdkh7fgHLWLJnQTrgCAADZCRquzGy/pHdKuidkOVeLYUEAAJC10D1XfyLpA5KWTTBmdqeZDZnZ0OjoaODqLFRmQjsAAMhYsHBlZj8macTdj7/Uee5+t7sPuvtgf39/qOosiTlXAAAgayF7rt4k6V1mdlLSJyW9xcw+GrC8NSsXmXMFAACyFSxcuftvuft+dz8o6Q5JX3H3nw1V3tWg5woAAGQt9+tcEa4AAECWChtRiLt/VdJXN6KstWApBgAAkLV891zFMT1XAAAgU/kOVwwLAgCAjBGu6g01Gt7qqgAAgG0i1+GqXEh+PvOuAABAVnIdrkox4QoAAGQr3+FqtueKeVcAACAjhCsRrgAAQHbyHa5iwhUAAMhWrsNVucicKwAAkK1chyt6rgAAQNZWDFdmFpnZGzeiMhttds5VhXAFAAAysmK4cveGpP+6AXXZcExoBwAAWVvtsOAXzewnzcyC1maDsYgoAADIWmGV5/0HSZ2S6mY2Jckkubv3BKvZBijFsSR6rgAAQHZWFa7cvTt0RVqBYUEAAJC11fZcyczeJem29ONX3f3zYaq0ceYntNdbXBMAALBdrGrOlZn9oaS7JD2Wvu5K921p9FwBAICsrbbn6h2SbknvHJSZfUTSA5I+GKpiG4EHNwMAgKytZRHR3qbtHRnXoyXouQIAAFlbbc/VH0h6wMzuU3Kn4G2SfitYrTZImUVEAQBAxlYMV2YWSWpIer2k1ykJV7/p7mcC1y04Hn8DAACytmK4cveGmf2Ku39K0uc2oE4bJopMxdiYcwUAADKz2jlXXzKzXzez68ysb/YVtGYbpBRH9FwBAIDMrHbO1S+k7+9r2ueSbsi2OhuvVCBcAQCA7Kx2ztUH3f1/bUB9NhzhCgAAZGnFYcF0bav3rXTeVlUqRMy5AgAAmWHOFXOuAABAhphzVYh5tiAAAMjMqsKVux8KXZFWKRUiFhEFAACZeclhQTP7QNP2Ty069gehKrWRygwLAgCADK005+qOpu3Fj7u5PeO6tAQT2gEAQJZWCle2zPZSn7cklmIAAABZWilc+TLbS33ekrhbEAAAZGmlCe03m9mYkl6q9nRb6ee2oDXbIOUiw4IAACA7Lxmu3D3eqIq0Cj1XAAAgS6tdRHTbYs4VAADIEuGKcAUAADJEuCpEqjDnCgAAZCT34Wp2EVH3bXHzIwAAaLHch6tSIWmCmTrhCgAArB/hKg1XPLwZAABkIVi4MrM2M/u2mX3XzB41s98JVdZ6lOKkCZjUDgAAsrDSIqLrUZH0FncfN7OipK+Z2T+6+zcDlrlmpUKylBcLiQIAgCwEC1eezBAfTz8W09emm9g0OyxIzxUAAMhC0DlXZhab2YOSRiR9yd2/tcQ5d5rZkJkNjY6OhqzOkghXAAAgS0HDlbvX3f0WSfslHTOzVy1xzt3uPujug/39/SGrs6TZOVcVwhUAAMjAhtwt6O4XJX1V0u0bUd5alItpzxVzrgAAQAZC3i3Yb2a96Xa7pB+WdCJUeVerzN2CAAAgQyHvFtwn6SNmFisJcZ9y988HLO+qMOcKAABkKeTdgg9JujXU9bNCuAIAAFlihfYCc64AAEB2CFfMuQIAABkiXPFsQQAAkCHCFXOuAABAhnIfrspx8mxBFhEFAABZyH24YkI7AADIEuGKYUEAAJCh3IerODLFkRGuAABAJnIfrqRkOQbCFQAAyALhSsnDm5lzBQAAskC4Ej1XAAAgO4QrJZPaCVcAACALhCsl4arCsCAAAMgA4UoMCwIAgOwQriSVCxErtAMAgEwQrjQ754oHNwMAgPUjXIkJ7QAAIDuEK6VzrpjQDgAAMkC4Ej1XAAAgO4QrSaVCTLgCAACZIFyJpRgAAEB2CFfi2YIAACA7hCslPVescwUAALJAuFKyiCjDggAAIAuEK6V3C9YbcvdWVwUAAGxxhCslw4LuUq1BuAIAAOtDuFLScyWJoUEAALBuhCvNhysmtQMAgPUiXImeKwAAkB3ClZI5VxLhCgAArB/hSk09V/V6i2sCAAC2OsKVknWuJOZcAQCA9SNciTlXAAAgO4QrSaU4lkS4AgAA60e4UvLgZkk8vBkAAKwb4UrcLQgAALJDuBJzrgAAQHYIV2peioFwBQAA1odwpflhQZZiAAAA60W4EutcAQCA7AQLV2Z2nZndZ2aPm9mjZnZXqLLWizlXAAAgK4WA165J+jV3/46ZdUs6bmZfcvfHApZ5VQhXAAAgK8F6rtz9tLt/J92+LOlxSdeGKm89WIoBAABkZUPmXJnZQUm3SvrWRpS3VoU4UmQ8uBkAAKxf8HBlZl2S/lbS+919bInjd5rZkJkNjY6Ohq7OskqFiJ4rAACwbkHDlZkVlQSrj7n7Z5Y6x93vdvdBdx/s7+8PWZ2XVIoJVwAAYP1C3i1okv5c0uPu/kehyslKuRiziCgAAFi3kD1Xb5L0c5LeYmYPpq93BCxvXUpxxDpXAABg3YItxeDuX5Nkoa6ftTJzrgAAQAZYoT3FhHYAAJAFwlWqVIiYcwUAANaNcJUqxZEqM4QrAACwPoSrFD1XAAAgC4SrFHOuAABAFghXKRYRBQAAWSBcpRgWBAAAWSBcpRgWBAAAWSBcpcoFVmgHAADrR7hKJXOu6q2uBgAA2OIIVyke3AwAALJAuEpxtyAAAMgC4SpVKkRquFSj9woAAKwD4SrVWS5Iki5NzbS4JgAAYCsjXKVevqdLkvS9s+MtrgkAANjKCFepowPdkqQTZ8ZaXBMAALCVEa5Se7rL2tlR1BNnLre6KgAAYAsjXKXMTEcGunWCcAUAANaBcNXk6ECPvnf2shoNb3VVAADAFkW4anJkoFuT1bqGL0y1uioAAGCLIlw1mZ3U/jiT2gEAwFUiXDV5xd4kXDGpHQAAXC3CVZPOckEH+joIVwAA4KoRrhZJ7hhkWBAAAFwdwtUiRwe69f1zE5qeqbe6KgAAYAsiXC1ydKBHDZeeGuExOAAAYO0IV4scmXsMDvOuAADA2hGuFjm4q0OlQqQnmHcFAACuAuFqkUIc6fCeLnquAADAVSFcLeHoQA/hCgAAXBXC1RKODnRr9HJF5yeqra4KAADYYghXS5if1M68KwAAsDaEqyXMPmOQldoBAMBaEa6W0N9dVl9nSSdOE64AAMDaEK6WYGY6srdbJ84SrgAAwNoQrpZxZKBbT569rEbDW10VAACwhRCulnF0oFuT1bqevzDZ6qoAAIAthHC1jNk7Bh9n3hUAAFgDwtUyXrG3W2bcMQgAANaGcLWMznJBB/o69MRZ1roCAACrR7h6CUf2dvMYHAAAsCbBwpWZ3WtmI2b2SKgyQjs60K2T5yY0PVNvdVUAAMAWEbLn6i8l3R7w+sEd3dejhktPnh1vdVUAAMAWESxcufs/Szof6vobgWcMAgCAtWr5nCszu9PMhsxsaHR0tNXVWeDgrk6VCxF3DAIAgFVrebhy97vdfdDdB/v7+1tdnQXiyHR4b5ee4DE4AABglVoerja7owM9LCQKAABWjXC1gqMD3To3XtGL45VWVwUAAGwBIZdi+ISkb0g6YmbDZvaLocoKaXZSO/OuAADAahRCXdjd3xPq2htp/o7By3rjy3e3uDYAAGCzY1hwBf1dZfV1lliOAQAArArhagVmpqMD3QwLAgCAVSFcrcKRgW597+y4Gg1vdVUAAMAmR7hahaMD3Zqaqeu585OtrgoAANjkCFercGSgR5J0/NkLLa4JAADY7AhXq3Djvh4d3tOl//S5R/X4aSa2AwCA5RGuVqFUiPSRXzimznJB77332xq+wPAgAABYGuFqla7pbddf/eIxTc/U9W/u/bbOT1RbXSUAALAJEa7W4BV7u3XPe1+n4QtT+oW/vF+T1VqrqwQAADYZwtUaHTvUp//2nlv10PBF/crHH9BMvdHqKgEAgE2EcHUVfvSVA/q9n3iVvnJiRL/9mYflzvpXAAAgEezZgtvdz/zA9RoZq+hDX35Se3rK+o0fPdrqKgEAgE2AcLUO7//hwxq5XNGH73ta7tK/+8EbtLOz1OpqAQCAFiJcrYOZ6ffe/UpNVmv6H199Wvd87fv68Zuu0c+94XrdvH+HzKzVVQQAABvMNtN8ocHBQR8aGmp1Na7KE2cu66PffFaf+c6wJqp1vfraHfq511+vH7/5GrWX4lZXDwAAZMzMjrv74BX7CVfZGq/U9NkHXtBff+Okvnd2XDvai/pXr7lWP3LjgAYP7lQx5h4CAAC2A8LVBnN33X/ygv76m8/qnx45o2q9oe62gm473K83H92jHzrSr91d5VZXEwAAXKXlwhVzrgIxMx071Kdjh/o0Xqnpa0+e030nRnTfEyP6+4dPy0y66dodevPRPfrBw/26af8OerUAANgG6LnaYO6uR0+N6SsnRvSVEyP67vBFuUudpVjHDvXpjS/brTe8bJdu3NejKGJCPAAAmxXDgpvU+YmqvvnMi/r60+f09adf1DOjE5Kk3o6iXn9ol15/Q59ed6hPRwd6FBO2AADYNBgW3KT6Okt6x6v36R2v3idJOnNpWt945py+/tSL+vrTL+oLj56RJHWXC3rtwZ163cE+ve5gn27av0NtRe5CBABgs6HnapMbvjCp+0+e1/0nL+j+75/XkyPjkqRSHOmm/Tv0mut36tbrenXrgZ0a2NHW4toCAJAfDAtuExcmqhp69oKGTp7X/SfP65FTY6rWkodH79vRplsP9OrW63bq1gO9euU1O1hjCwCAQBgW3CZ2dpb0thv36m037pUkVWp1PX76sh547oIeeO6iHnj+gv7h4WQoMY5Mh/d06dXX7tBN+3fo1ft7dXSgm+FEAAACoudqGxq9XNGDz1/Uw8MX9dALl/TQ8CWdn6hKkgqR6chAt151zQ7deE2PbrymR0cHutXdVmxxrQEA2FoYFswxd9epS9NJ2Bq+pIdfuKRHXrikC5Mzc+dcv6tDN+7rSV7X9OjIQLeu7W3n+YgAACyDYcEcMzNd29uua3vbdfurkrsS3V1nxyp67PQlPXZqTI+dHtNjp8b0j4+cmfteV7mgV+zt0pGBbh3Z261XDHTr6ECP+jpLrfopAABsevRcYYHxSk0nTo/pibOX9cSZ9HX2si429XLt6izp5Xu6rngN9LTR0wUAyA16rrAqXeWCBg/2afBg39w+d9fI5cpc2Hpy5LKeGhnX//nuKY1N1xZ892X9nTq0u1OHdnfpUH+nbtidfO4s80cNAJAP/IuHFZmZ9va0aW9Pm257Rf/cfnfX6HhFT42M6+mRcT01Mq6nRsd1/8kL+rsHTy24xt6esg7t7tT1fZ26fndH8r6rQwd2daiHyfQAgG2EcIWrZmba092mPd1teuPLdi84NlWt69nzE/r+6ISeOTeh76evL58Y0bnxyoJz+zpLOtDXoQN9Hdq/s13X9XXoup3J9jW97SoVeKA1AGDrIFwhiPZSrKMDPTo60HPFsfFKTc+9OKnnzk/o5IuTevbFST374oQeeP6C/v7h06o35ucBRiYN9LRp/84OXdPbpmvTwHVNOkH/mt52dTHkCADYRPhXCRuuq1yYW2NrsVq9oTNj03r+/JSGL0zq+QvJ+/D5KQ09e0Gff+i0ao2FN2HsaC9q3442DexoS9572rVvR5v29Saf9/S0qbtcYLI9AGBDEK6wqRTiSPt3dmj/zg5Ju644Xm+4Ri5P69TFKQ1fmNKpi9N64eKkzlyq6MzYlB554ZLOjVev+F57MdbenrL2pHPH9naXtbenTXt6yurvKqu/u6w93W3qaSeEAQDWh3CFLSWOTPt2tGvfjna99vqlz6nU6hoZq+j0pWmdvjSls2PTOjtW0dmxaY2MVfTQ8EWdHZvW9Ezjiu+W4kj93WXt7k5C1+6uknZ3lbWrq6RdXWXt7kzfu0rq7SgpjghiAICFCFfYdsqFOJkU39ex7DnursuVms5emtboeEWjl5PXufFqsj1e0fCFSX13+KLOT1QXzAObZSb1thfV11lqepXV11nUzo5S8uosqrejpL70c3dbQRGBDAC2NcIVcsnM1NNWVE9bUYf3dr/kuY2G69LUjM6NJ+HrxYmKzl2u6PxEVecnq8n7RFXfPzeh489e0IXJmSXDmJRM0O/tKKm3vagdHUXtaC+qtz0JYD3p9o701dNeVE97IdluK6qjFDNkCQBbAOEKWEEUmXZ2lrSzs6TDe1c+v9FwXZ6u6cJkVRcmq7o4OaPzE/PbFyarujQ1o0tTM3pxvKpnRid0cbK6YEHWpRQiU3dbQd1txfS9oJ624tznnvRYV1tBXeWCutoK6k7fu8rJq7NcUDFmaQsACIlwBWQsiizpleoo6qA6V/29esM1NjWjsekZjU3VdGlue2Zu+9LUjC5P19LXjJ47P6mx2X2Vlw5ns0qFKA1asTpLSeDqLBfUVY7VUSqosxSro5y+l5Lz2ksFdRRjdaTndJRitRdjdaTnlAsRw50AkCJcAZtE3NRDdjUaDddEtabxSk3j0+l7un05fZ+o1DReTd4nKnWNV5LtS5NVnbpY12SlpolqXROV2hVLXqykrRipo1RQezFeuF2K1VaI1F6K1VaI1V6KVS5G6XmxyoVIbel32grpvmI0d6xcSN+b9pXiiCFSAJsW4QrYJqLI0iHCorRj/der1hqarCZha6pa02S1rolKXVMzyfZkta6p2feZuqZn6pqs1jRVbcxtT1brujQ1o5GZ+XOmqnVN1xqq1q68W3MtSoUoDV9JAJv9XErDV2nRdvM5xdhUKkQqxsmrnG7P7zOV0mPF9PxyIVIhmj9eSN9nr1GITcUoeS9ERvgDcixouDKz2yV9SFIs6R53/8OQ5QHIThJOSupd/qbLdak3XJVaXdMzSRir1JL35NXQdK2uam3+WKXWUGV2e6auSr2hykxD1XoS1Cq1hqq1evqevC5P15LtRefM1F0z9caae+fWohibCmnYKsaRCpHNhbA4agpi6bFCZGkwixZup+cXIlOcHovnzo8UR7pif9y0HUWm2Ob3zb2a9s2eM3d+ZIps/rwoUtP2/HejpuORNR2PTJFp7hqRJZ8JnMiLYOHKzGJJH5b0NknDku43s8+5+2OhygSwdcSRpfO3WleHRsNVrTc0k4avar2hWn3hvuTd02ONpmDW0EzNNdNIvjOTHqul351p+Nz5tblzXPXG/LFa3TXTSPbV6q7pmYZqjbpq9YbqjfkAWE9fs9sz6fFa3VV3X/bu1M3GTEkAawpkkVmyf1EIi5u2rzi3abv5WmYmk+aC3eJzTE2fZ6+dviffu/K8uXel51ly/dlzltoXpSFy4XfT/Yv2zV0n/YIt8b3ZUDpbn8XfleZ/g+aOzddt8bUXfK9pn2bPbbpeUv7suQvLW/z9xdec+9aC/XbFOXPlzx7Qwnos/LxEXeaLmjsWmfQDN1y5EPVGCdlzdUzSU+7+jCSZ2SclvVsS4QrAphBFprYomee1lbm7Gi7VGo25ENZoJGGu4fPhrN6YD2OL9zWWOCf5rpq2F15v9njDF+5319w1fNE5s9/xuc+aP8+T7zbc1Zj7juaONdJjvuj43L50W1p4jVqjIa+n50lz15w9x9M2nCt79ryGp8dmy0jPU9PnRd9tPl/p8flz53/Pgu+m30F22oqRTvze21tWfshwda2k55s+D0v6gcUnmdmdku6UpAMHDgSsDgBsT0lPjxRHWzskYmHwag5ls+HrilCnNJilx2fPXXzcNR/2fLlzvbkeC8u9Mgh603lXXrP5GpKWvHbz92d/+/yVm7+z8BoLylvmO62+eTlkuFrqp12Rzd39bkl3S9Lg4CDZHQCQW7NDeZIUL/nPKLaCkKsJDku6runzfkmnApYHAADQciHD1f2SDpvZITMrSbpD0ucClgcAANBywYYF3b1mZr8i6Z+ULMVwr7s/Gqo8AACAzSDoOlfu/g+S/iFkGQAAAJsJT3AFAADIEOEKAAAgQ4QrAACADBGuAAAAMkS4AgAAyBDhCgAAIEOEKwAAgAwRrgAAADJEuAIAAMgQ4QoAACBDhCsAAIAMmbu3ug5zzGxU0rOBi9kt6VzgMrY62mh1aKeV0UarQzutDu20MtpodbJqp+vdvX/xzk0VrjaCmQ25+2Cr67GZ0UarQzutjDZaHdppdWinldFGqxO6nRgWBAAAyBDhCgAAIEN5DFd3t7oCWwBttDq008poo9WhnVaHdloZbbQ6Qdspd3OuAAAAQspjzxUAAEAwhCsAAIAM5SZcmdntZvaEmT1lZh9sdX02CzO718xGzOyRpn19ZvYlM3syfd/Zyjq2mpldZ2b3mdnjZvaomd2V7qedmphZm5l928y+m7bT76T7aadFzCw2swfM7PPpZ9poETM7aWYPm9mDZjaU7qOdmphZr5l92sxOpH8/vYE2WsjMjqR/hmZfY2b2/tDtlItwZWaxpA9LerukGyW9x8xubG2tNo2/lHT7on0flPRldz8s6cvp5zyrSfo1d/8Xkl4v6X3pnx/aaaGKpLe4+82SbpF0u5m9XrTTUu6S9HjTZ9poaW9291ua1iOinRb6kKQvuPtRSTcr+TNFGzVx9yfSP0O3SHqtpElJn1XgdspFuJJ0TNJT7v6Mu1clfVLSu1tcp03B3f9Z0vlFu98t6SPp9kck/cRG1mmzcffT7v6ddPuykr/ArhXttIAnxtOPxfTlop0WMLP9kt4p6Z6m3bTR6tBOKTPrkXSbpD+XJHevuvtF0UYv5a2Snnb3ZxW4nfISrq6V9HzT5+F0H5a2191PS0mwkLSnxfXZNMzsoKRbJX1LtNMV0uGuByWNSPqSu9NOV/oTSR+Q1GjaRxtdySV90cyOm9md6T7aad4NkkYl/UU6xHyPmXWKNnopd0j6RLodtJ3yEq5siX2sQYE1MbMuSX8r6f3uPtbq+mxG7l5Pu9/3SzpmZq9qcZU2FTP7MUkj7n681XXZAt7k7q9RMp3jfWZ2W6srtMkUJL1G0p+5+62SJpTzIcCXYmYlSe+S9DcbUV5ewtWwpOuaPu+XdKpFddkKzprZPklK30daXJ+WM7OikmD1MXf/TLqbdlpGOjzxVSXz+WineW+S9C4zO6lkesJbzOyjoo2u4O6n0vcRJXNkjol2ajYsaTjtHZakTysJW7TR0t4u6Tvufjb9HLSd8hKu7pd02MwOpen1Dkmfa3GdNrPPSXpvuv1eSf+7hXVpOTMzJfMaHnf3P2o6RDs1MbN+M+tNt9sl/bCkE6Kd5rj7b7n7fnc/qOTvoa+4+8+KNlrAzDrNrHt2W9KPSHpEtNMcdz8j6XkzO5Luequkx0QbLec9mh8SlAK3U25WaDezdyiZ6xBLutfdf7+1NdoczOwTkn5I0m5JZyX9R0l/J+lTkg5Iek7ST7n74knvuWFm/1LS/5P0sObnyfy2knlXtFPKzG5SMjE0VvI/bp9y9981s12ina5gZj8k6dfd/cdoo4XM7AYlvVVSMvz1cXf/fdppITO7RcmNESVJz0j6eaX/7Yk2mmNmHUrmXd/g7pfSfUH/LOUmXAEAAGyEvAwLAgAAbAjCFQAAQIYIVwAAABkiXAEAAGSIcAUAAJAhwhWATc3M6oueap/ZKtRmdtDMHsnqegAgJeuHAMBmNpU+UgcAtgR6rgBsSWZ20sz+i5l9O329PN1/vZl92cweSt8PpPv3mtlnzey76euN6aViM/ufZvaomX0xXV1eZvarZvZYep1PtuhnAtiCCFcANrv2RcOCP910bMzdj0n670qewKB0+6/c/SZJH5P0p+n+P5X0f939ZiXPYHs03X9Y0ofd/ZWSLkr6yXT/ByXdml7nl8L8NADbESu0A9jUzGzc3buW2H9S0lvc/Zn0wdpn3H2XmZ2TtM/dZ9L9p919t5mNStrv7pWmaxyU9CV3P5x+/k1JRXf/z2b2BUnjSh4H9XfuPh74pwLYJui5ArCV+TLby52zlErTdl3zc1HfKenDkl4r6biZMUcVwKoQrgBsZT/d9P6NdPvrku5It39G0tfS7S9L+mVJMrPYzHqWu6iZRZKuc/f7JH1AUq+kK3rPAGAp/J8YgM2u3cwebPr8BXefXY6hbGbfUvI/iu9J9/2qpHvN7DckjUr6+XT/XZLuNrNfVNJD9cuSTi9TZizpo2a2Q5JJ+mN3v5jR7wGwzTHnCsCWlM65GnT3c62uCwA0Y1gQAAAgQ/RcAQAAZIieKwAAgAwRrgAAADJEuAIAAMgQ4QoAACBDhCsAAIAM/X/3B5RfruITjgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#경사하강법 실습\n",
    "\n",
    "#샘플에 활용할 데이터 셋 만들기\n",
    "def make_linear(w=0.5, b=0.8, size=50,noise=10):\n",
    "    x = np.random.rand(size)\n",
    "    y = w*x+b\n",
    "    noise = np.random.uniform(-abs(noise),abs(noise),size = y.shape)\n",
    "    yy = y + noise\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot(x,y,color='r',label=f'y={w}*x+{b}')\n",
    "    plt.scatter(x,yy,label ='data')\n",
    "    plt.legend(fontsize=20)\n",
    "    plt.show()\n",
    "    print(f'w:{w},b:{b}')\n",
    "    return x,yy\n",
    "\n",
    "x,y = make_linear(w=0.3,b=0.5,size=100,noise=0.01)\n",
    "\n",
    "#최대 반복 횟수\n",
    "num_epoch = 100\n",
    "\n",
    "#학습률(learnig_rate)\n",
    "learning_rate = 0.005\n",
    "\n",
    "#에러기록\n",
    "errors = []\n",
    "\n",
    "#random 한 값으로 w,b를 초기화\n",
    "w = np.random.uniform(low = 0.0, high = 1.0)\n",
    "b = np.random.uniform(low = 0.0, high = 1.0)\n",
    "\n",
    "for epoch in range(num_epoch):\n",
    "    #Hypothesis 정의\n",
    "    y_hat = w*x+b\n",
    "    \n",
    "    #Loss Function 정의\n",
    "    error = 0.5*((y_hat - y)**2).sum()\n",
    "    if error < 0.005:\n",
    "        break\n",
    "    #Gradient 미분 계산\n",
    "    w = w - learning_rate*((y_hat - y)*x).sum()\n",
    "    b = b - learning_rate*(y_hat -y).sum()\n",
    "    \n",
    "    errors.append(error)\n",
    "    \n",
    "    if epoch%5 == 0:\n",
    "        print(\"{0:2}     w = {1:.5f}, b = {2:.5f}     error = {3:.5f}\".format(epoch, w, b, error))\n",
    "\n",
    "print(\"----\" * 15)\n",
    "print(\"{0:2}     w = {1:.1f}, b = {2:.1f}     error = {3:.5f}\".format(epoch, w, b, error))\n",
    "\n",
    "plt.figure(figsize = (10,7))\n",
    "plt.plot(errors)\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Error')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "931e65fb8f6b94005bf1e95e6550bb9bf9f82953a045b69934725ecc774a59a6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
